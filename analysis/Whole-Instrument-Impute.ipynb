{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True  True ...,  True  True  True]\n",
      " [ True  True  True ...,  True  True  True]\n",
      " [ True  True False ...,  True  True  True]\n",
      " ..., \n",
      " [False  True False ..., False False False]\n",
      " [False  True False ..., False False False]\n",
      " [False  True False ..., False False False]]\n",
      "(671,)\n",
      "(672,)\n",
      "Autism\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "\n",
    "Z = np.genfromtxt('../data/i2i_impute_logloss_realfill_Z5.csv', delimiter=',', skip_header=True)\n",
    "Z = Z[:, 1:]\n",
    "m, n = Z.shape\n",
    "\n",
    "missing = np.genfromtxt('../data/all_samples_filtered.csv', delimiter=',', skip_header=True)\n",
    "missing = np.isnan(missing[:, 1:])\n",
    "print(missing)\n",
    "\n",
    "adir_indices = range(0, 77)\n",
    "ados_indices = range(77, 123)\n",
    "\n",
    "adir_test_indices = np.loadtxt('../data/adir_test_indices.csv').astype(int)\n",
    "ados_test_indices = np.loadtxt('../data/ados_test_indices.csv').astype(int)\n",
    "\n",
    "print(adir_test_indices.shape)\n",
    "print(ados_test_indices.shape)\n",
    "\n",
    "adir_train_indices = list(set(range(m))-set(adir_test_indices))\n",
    "ados_train_indices = list(set(range(m))-set(ados_test_indices))\n",
    "\n",
    "with open('../data/all_samples_filtered_labels.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    key_to_index = dict([(h, i) for i, h in enumerate(header[1:])])\n",
    "    data_labels = [x[1:] for x in reader]\n",
    "    \n",
    "def get_label(i, key):\n",
    "    return data_labels[i][key_to_index[key]]\n",
    "        \n",
    "print(get_label(0, 'ADIR:diagnosis'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS0AAAD3CAYAAABIMQITAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e7f6588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cay = plt.matshow(Z[ados_train_indices, :][:100, :], cmap='hot')\n",
    "plt.colorbar(cay)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561\n",
      "0.399420604744 0.397504456328 11046 561\n",
      "518\n",
      "0.821435575603 0.828185328185 10198 518\n",
      "496\n",
      "0.242957022414 0.25 9726 496\n",
      "455\n",
      "0.703436619718 0.738461538462 8875 455\n",
      "267\n",
      "0.255553515697 0.265917602996 5447 267\n",
      "267\n",
      "0.745684906353 0.704119850187 5446 267\n",
      "275\n",
      "0.772318868285 0.778181818182 5231 275\n",
      "267\n",
      "0.492809734513 0.513108614232 5424 267\n",
      "363\n",
      "0.755690440061 0.771349862259 7249 363\n",
      "525\n",
      "0.575452716298 0.586666666667 10437 525\n",
      "169\n",
      "0.860280658938 0.828402366864 3278 169\n",
      "158\n",
      "0.244378306878 0.284810126582 3024 158\n",
      "48\n",
      "0.632835820896 0.729166666667 1005 48\n",
      "542\n",
      "0.777120870871 0.789667896679 10656 542\n",
      "543\n",
      "0.81592039801 0.821362799263 10653 543\n",
      "72\n",
      "0.544921875 0.583333333333 1536 72\n",
      "531\n",
      "0.462360461788 0.455743879473 10481 531\n",
      "267\n",
      "0.781617647059 0.812734082397 5440 267\n",
      "267\n",
      "0.867328188166 0.883895131086 5442 267\n",
      "281\n",
      "0.265983224604 0.220640569395 5365 281\n",
      "253\n",
      "0.852491961415 0.822134387352 4976 253\n",
      "277\n",
      "0.192373041344 0.187725631769 5297 277\n",
      "275\n",
      "0.761185468451 0.763636363636 5230 275\n",
      "3\n",
      "0.589928057554 0.0 139 3\n",
      "373\n",
      "0.581458389808 0.560321715818 7378 373\n",
      "542\n",
      "0.855185358986 0.861623616236 10655 542\n",
      "374\n",
      "0.795387105476 0.799465240642 7414 374\n",
      "373\n",
      "0.713235294118 0.73726541555 7344 373\n",
      "173\n",
      "0.85308056872 0.843930635838 3376 173\n",
      "172\n",
      "0.741250373916 0.709302325581 3343 172\n",
      "48\n",
      "0.56374501992 0.666666666667 1004 48\n",
      "173\n",
      "0.536751630113 0.537572254335 3374 173\n",
      "48\n",
      "0.602 0.729166666667 1000 48\n",
      "173\n",
      "0.876407824541 0.861271676301 3374 173\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 77)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-6caffa6b1e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtrain_attempts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_num_attempts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmissing_test_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \"\"\"\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    414\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 416\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 77)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "train_correct = 0\n",
    "train_attempts = 0\n",
    "test_correct = 0\n",
    "test_attempts = 0\n",
    "overall_predictions = []\n",
    "overall_real = []\n",
    "\n",
    "adir_Z = Z[:, adir_indices]\n",
    "ados_Z = Z[:, ados_indices]\n",
    "\n",
    "for i in ados_indices:\n",
    "    train_data = adir_Z[ados_train_indices, :]\n",
    "    test_data = adir_Z[ados_test_indices, :]\n",
    "    train_y = Z[ados_train_indices, i]\n",
    "    test_y = Z[ados_test_indices, i]\n",
    "    \n",
    "    missing_train_y = missing[ados_train_indices, i]\n",
    "    missing_test_y = missing[ados_test_indices, i]\n",
    "        \n",
    "    model = LogisticRegression(fit_intercept=False)\n",
    "    model.fit(train_data, train_y)\n",
    "    \n",
    "    train_predictions = model.predict(train_data[~missing_train_y])\n",
    "    train_num_correct = sum([x for x in train_predictions * train_y[~missing_train_y] if x == 1])\n",
    "    train_num_attempts = train_predictions.shape[0]\n",
    "    train_errors.append(1.0*train_num_correct/train_num_attempts)\n",
    "    train_correct += train_num_correct\n",
    "    train_attempts += train_num_attempts\n",
    "    \n",
    "    test_predictions = model.predict(test_data[~missing_test_y])\n",
    "    print(len(test_predictions))\n",
    "    \n",
    "    overall_predictions.extend(test_predictions)\n",
    "    overall_real.extend(test_y[~missing_test_y])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_y[~missing_test_y], test_predictions, pos_label=1)\n",
    "    plt.plot(fpr, tpr, '-', c='blue')\n",
    "    test_num_correct = sum([x for x in test_predictions * test_y[~missing_test_y] if x == 1])\n",
    "    test_num_attempts = test_predictions.shape[0]\n",
    "    test_errors.append(1.0*test_num_correct/test_num_attempts)\n",
    "    test_correct += test_num_correct\n",
    "    test_attempts += test_num_attempts\n",
    "\n",
    "    print(train_errors[-1], test_errors[-1], train_num_attempts, test_num_attempts)\n",
    "print('Average Accuracy', 1.0*train_correct/train_attempts, 1.0*test_correct/test_attempts)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(overall_real, overall_predictions, pos_label=1)\n",
    "plt.plot(fpr, tpr, '-', c='red')\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813216656608 0.8 6628 745\n",
      "0.714695752009 0.734299516908 1742 207\n",
      "0.818767123288 0.815136476427 7300 806\n",
      "0.826614001634 0.841911764706 7342 816\n",
      "0.950842696629 0.949790794979 6408 717\n",
      "0.924013495673 0.92005242464 6817 763\n",
      "0.743328100471 0.74025974026 1274 154\n",
      "0.757125712571 0.737333333333 6666 750\n",
      "0.957456404089 0.949265687583 6652 749\n",
      "0.948356102687 0.949129852744 6661 747\n",
      "0.942731943185 0.934316353887 6618 746\n",
      "0.929771908764 0.931726907631 6664 747\n",
      "0.781163006496 0.76275862069 6466 725\n",
      "0.769095182139 0.747572815534 1702 206\n",
      "0.674764181419 0.655172413793 7739 870\n",
      "0.848871807587 0.852842809365 8066 897\n",
      "0.690010167768 0.664009111617 7868 878\n",
      "0.612945406996 0.597968069666 6118 689\n",
      "0.839919417325 0.829370629371 6453 715\n",
      "0.926754987056 0.925207756233 6567 722\n",
      "0.961687170475 0.966876971609 5690 634\n",
      "0.652409830833 0.65 6266 700\n",
      "0.657700508447 0.627565982405 6097 682\n",
      "0.650031786395 0.61087267525 6292 699\n",
      "0.580670799555 0.57 6291 700\n",
      "0.861373250895 0.871201157742 6146 691\n",
      "0.650734038921 0.657534246575 5858 657\n",
      "0.760167236792 0.782212086659 7893 877\n",
      "0.678363313909 0.641230068337 7894 878\n",
      "0.649189463019 0.607753705815 7896 877\n",
      "0.783906882591 0.785227272727 7904 880\n",
      "0.853484139366 0.874133949192 7692 866\n",
      "0.887956250795 0.902272727273 7863 880\n",
      "0.898971950755 0.880546075085 7879 879\n",
      "0.934609030837 0.927696078431 7264 816\n",
      "0.873262782099 0.88698630137 7843 876\n",
      "0.750411132195 0.780681818182 7905 880\n",
      "0.723318158827 0.740614334471 7908 879\n",
      "0.852249747219 0.866894197952 7912 879\n",
      "0.697939056771 0.704545454545 7909 880\n",
      "0.779815353484 0.785227272727 7907 880\n",
      "0.737700771468 0.751136363636 7907 880\n",
      "0.758978249874 0.747727272727 7908 880\n",
      "0.742488172868 0.746849942726 7821 873\n",
      "0.882058707384 0.884798099762 7597 842\n",
      "0.801991722711 0.804597701149 7732 870\n",
      "0.8203075359 0.846590909091 7869 880\n",
      "0.790656341247 0.785227272727 7877 880\n",
      "0.832486019319 0.826879271071 7868 878\n",
      "0.942366306456 0.955828220859 7218 815\n",
      "0.877400768246 0.867605633803 6248 710\n",
      "0.91356542617 0.939393939394 6664 759\n",
      "0.680420199975 0.67007963595 7901 879\n",
      "0.67744904668 0.694736842105 7605 855\n",
      "0.829903455285 0.855835240275 7872 874\n",
      "0.546546926385 0.51763367463 7906 879\n",
      "0.790026578914 0.825740318907 7901 878\n",
      "0.703880366121 0.721649484536 7757 873\n",
      "0.632937044042 0.644578313253 7402 830\n",
      "0.650102986612 0.657894736842 7768 874\n",
      "0.744875596236 0.729667812142 7757 873\n",
      "0.645083932854 0.627994955864 7089 793\n",
      "0.651909941816 0.643913538111 7906 879\n",
      "0.634800202327 0.629124004551 7908 879\n",
      "0.907842870735 0.913730255164 7357 823\n",
      "0.562319979052 0.569605568445 7638 862\n",
      "0.679909345421 0.668625146886 7501 851\n",
      "0.573980271927 0.54652532391 7502 849\n",
      "0.561778814988 0.534562211982 7713 868\n",
      "0.887574768896 0.878640776699 7356 824\n",
      "0.897681647455 0.90289017341 7721 865\n",
      "0.795157068063 0.772463768116 6112 690\n",
      "0.645236508994 0.614934114202 6004 683\n",
      "0.88495720869 0.860907759883 6076 683\n",
      "0.899639816634 0.914616497829 6108 691\n",
      "0.801710863986 0.780597014925 5845 670\n",
      "0.871037704371 0.867346938776 5994 686\n",
      "Average Accuracy 0.776138972047 0.773894590248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "train_correct = 0\n",
    "train_attempts = 0\n",
    "test_correct = 0\n",
    "test_attempts = 0\n",
    "for i in range(adir_Z.shape[1]):\n",
    "    train_data = ados_Z[train_indices, :]\n",
    "    test_data = ados_Z[test_indices, :]\n",
    "    train_y = adir_Z[train_indices, i]\n",
    "    test_y = adir_Z[test_indices, i]\n",
    "    real_train_y = adir_data[train_indices, i]\n",
    "    real_test_y = adir_data[test_indices, i]\n",
    "    \n",
    "    model = LogisticRegression(fit_intercept=False)\n",
    "    model.fit(train_data, train_y)\n",
    "    \n",
    "    train_predictions = model.predict(train_data[real_train_y != 0])\n",
    "    train_num_correct = sum([x for x in train_predictions * real_train_y[real_train_y != 0] if x == 1])\n",
    "    train_num_attempts = train_predictions.shape[0]\n",
    "    train_errors.append(1.0*train_num_correct/train_num_attempts)\n",
    "    train_correct += train_num_correct\n",
    "    train_attempts += train_num_attempts\n",
    "    \n",
    "    test_predictions = model.predict(test_data[real_test_y != 0])\n",
    "    test_num_correct = sum([x for x in test_predictions * real_test_y[real_test_y != 0] if x == 1])\n",
    "    test_num_attempts = test_predictions.shape[0]\n",
    "    test_errors.append(1.0*test_num_correct/test_num_attempts)\n",
    "    test_correct += test_num_correct\n",
    "    test_attempts += test_num_attempts\n",
    "\n",
    "    print(train_errors[-1], test_errors[-1], train_num_attempts, test_num_attempts)\n",
    "print('Average Accuracy', 1.0*train_correct/train_attempts, 1.0*test_correct/test_attempts)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
