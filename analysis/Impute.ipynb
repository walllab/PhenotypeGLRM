{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition describe(AbstractArray) in module StatsBase at /Users/kelley/.julia/v0.5/StatsBase/src/scalarstats.jl:560 overwritten in module DataFrames at /Users/kelley/.julia/v0.5/DataFrames/src/abstractdataframe/abstractdataframe.jl:407.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9100,185)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames\n",
    "\n",
    "# To run this notebook, you need to have a data file available.\n",
    "# You can either run the phenotype preprocessing scripts in ../preprocessing directory\n",
    "# Or scp -r username@sherlock.stanford.edu:/scratch/PI/dpwall/DATA/phenotypes/jsonschema ../data\n",
    "\n",
    "# Data\n",
    "df = readtable(\"../data/all_samples_both_instruments_filtered.csv\", nastrings=[\"None\"])\n",
    "samples = df[:, 1:1]\n",
    "df = df[:, 2:end] # Remove identifier\n",
    "\n",
    "# Binarize Data\n",
    "[df[df[nm].> 0, nm] = 1 for nm in names(df)]\n",
    "[df[df[nm].== 0, nm] = -1 for nm in names(df)]\n",
    "[df[isna(df[nm]), nm] = 0 for nm in names(df)]\n",
    "\n",
    "m, n = size(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1344633"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Form sparse array\n",
    "all_data = sparse(Array(df))\n",
    "p = size(nonzeros(all_data), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134464,)\n",
      "(67232,)\n",
      "(1151283,)\n"
     ]
    }
   ],
   "source": [
    "# Split out testing data\n",
    "all_indices = 1:p\n",
    "held_out_test_indices = sample(all_indices, ceil(Integer, 0.1 * p))\n",
    "other_indices = setdiff(all_indices, held_out_test_indices)\n",
    "test_indices = sample(other_indices, ceil(Integer, 0.05 * p))\n",
    "train_indices = setdiff(other_indices, test_indices)\n",
    "\n",
    "train_data = copy(all_data)\n",
    "nonzeros(train_data)[test_indices] = 0\n",
    "dropzeros!(train_data)\n",
    "\n",
    "test_data = copy(all_data)\n",
    "nonzeros(test_data)[train_indices] = 0\n",
    "dropzeros!(test_data)\n",
    "\n",
    "println(size(held_out_test_indices))\n",
    "println(size(test_indices))\n",
    "println(size(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140:185"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adir_indices = 1:139\n",
    "ados_indices = 140:n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Both instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 405456.1512174418\n",
      "Iteration 20: objective value = 369285.6046747477\n",
      "Iteration 30: objective value = 352511.0790024653\n",
      "Iteration 40: objective value = 340637.8285164097\n",
      "obj went up to 341357.68237954896; reducing step size to 4.927992098487262\n",
      "obj went up to 339983.59112894326; reducing step size to 3.449594468941083\n",
      "obj went up to 338636.6256845631; reducing step size to 2.535451934671696\n",
      "Iteration 50: objective value = 336797.32739381364\n",
      "obj went up to 336523.5536409644; reducing step size to 2.1573003712176275\n",
      "Iteration 60: objective value = 334009.2009904441\n",
      "obj went up to 333982.16361590364; reducing step size to 2.124876784895767\n",
      "Iteration 70: objective value = 331909.8877313254\n",
      "obj went up to 332014.84834226756; reducing step size to 2.092940515483502\n",
      "obj went up to 330298.16004879447; reducing step size to 2.061484238751859\n",
      "Iteration 80: objective value = 330091.6795124915\n",
      "obj went up to 328716.51639047475; reducing step size to 2.0305007405528577\n",
      "Iteration 90: objective value = 327991.4474435221\n",
      "obj went up to 327290.12751688936; reducing step size to 1.999982915165029\n",
      "Iteration 100: objective value = 326295.68593849964\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 395960.93463947676\n",
      "Iteration 20: objective value = 358580.72324566165\n",
      "Iteration 30: objective value = 341319.79786164535\n",
      "obj went up to 332920.35214079334; reducing step size to 4.256984859939325\n",
      "Iteration 40: objective value = 331618.04319216864\n",
      "obj went up to 331770.97750388115; reducing step size to 3.285328065658175\n",
      "obj went up to 328829.3933217991; reducing step size to 2.414716128258759\n",
      "Iteration 50: objective value = 326477.4093821546\n",
      "obj went up to 325682.215161943; reducing step size to 2.3784236592674355\n",
      "Iteration 60: objective value = 323311.8319343156\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 388975.71760010556\n",
      "Iteration 20: objective value = 349568.2038544385\n",
      "Iteration 30: objective value = 330737.2477754322\n",
      "Iteration 40: objective value = 320276.5759950788\n",
      "obj went up to 322619.1945577202; reducing step size to 4.693325808083107\n",
      "obj went up to 319686.6392016367; reducing step size to 3.285328065658175\n",
      "obj went up to 316411.17207891966; reducing step size to 2.535451934671697\n",
      "Iteration 50: objective value = 313511.19229329086\n",
      "obj went up to 312934.9746998629; reducing step size to 2.26516538977851\n",
      "Iteration 60: objective value = 309999.46475172794\n",
      "obj went up to 309726.65859541274; reducing step size to 2.2311206241405563\n",
      "Iteration 70: objective value = 307285.85515112436\n",
      "obj went up to 307361.4827154726; reducing step size to 2.1975875412576777\n",
      "Iteration 80: objective value = 305048.5488632882\n",
      "obj went up to 305244.6056091386; reducing step size to 2.164558450689452\n",
      "obj went up to 303118.79895010864; reducing step size to 2.0305007405528577\n",
      "Iteration 90: objective value = 302645.45058473974\n",
      "obj went up to 301466.2928269641; reducing step size to 2.0999820609232804\n",
      "Iteration 100: objective value = 300812.9092862465\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 382132.0137696962\n",
      "Iteration 20: objective value = 341390.95944746584\n",
      "Iteration 30: objective value = 320906.1922513455\n",
      "Iteration 40: objective value = 306287.3076509795\n",
      "obj went up to 305989.5034419477; reducing step size to 5.174391703411625\n",
      "obj went up to 304637.79942939186; reducing step size to 3.6220741923881374\n",
      "obj went up to 302573.2935415595; reducing step size to 2.6622245314052813\n",
      "Iteration 50: objective value = 300531.7926562209\n",
      "obj went up to 299534.54932839127; reducing step size to 2.3784236592674346\n",
      "Iteration 60: objective value = 297011.2914345881\n",
      "obj went up to 296887.48399247456; reducing step size to 2.2311206241405555\n",
      "Iteration 70: objective value = 294091.50925245543\n",
      "obj went up to 294101.77940114844; reducing step size to 2.1975875412576773\n",
      "Iteration 80: objective value = 291814.945021329\n",
      "obj went up to 291965.16903275746; reducing step size to 2.164558450689452\n",
      "obj went up to 290019.6247045597; reducing step size to 2.1320257775805005\n",
      "Iteration 90: objective value = 289810.14564346307\n",
      "obj went up to 288283.74884244293; reducing step size to 2.0999820609232804\n",
      "Iteration 100: objective value = 287486.01197548123\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 372191.96848637564\n",
      "Iteration 20: objective value = 330145.84264083917\n",
      "Iteration 30: objective value = 308798.0516737544\n",
      "obj went up to 301731.0248042812; reducing step size to 4.469834102936292\n",
      "Iteration 40: objective value = 298120.9921749347\n",
      "obj went up to 298111.60088993364; reducing step size to 3.1288838720554044\n",
      "obj went up to 293290.7530301036; reducing step size to 2.5354519346716966\n",
      "Iteration 50: objective value = 290262.962300512\n",
      "obj went up to 288817.6149977558; reducing step size to 2.497344842230807\n",
      "Iteration 60: objective value = 286294.7968909589\n",
      "obj went up to 285919.9569429644; reducing step size to 2.3426766553475837\n",
      "Iteration 70: objective value = 283187.2938702849\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 365421.54746203567\n",
      "Iteration 20: objective value = 321028.0813249854\n",
      "Iteration 30: objective value = 297824.33466417616\n",
      "obj went up to 285999.1078312481; reducing step size to 4.469834102936292\n",
      "Iteration 40: objective value = 284937.5360754046\n",
      "obj went up to 283920.2215930613; reducing step size to 3.1288838720554044\n"
     ]
    }
   ],
   "source": [
    "using LowRankModels\n",
    "\n",
    "for k=16:25\n",
    "    losses = LogisticLoss()\n",
    "    rx = ZeroReg()\n",
    "    ry = ZeroReg()\n",
    "    glrm = GLRM(train_data, losses, rx, ry, k, offset=false, scale=false);\n",
    "    init_svd!(glrm);\n",
    "\n",
    "    X,Y,ch = fit!(glrm, verbose=true, max_iter=1000); # fit GLRM\n",
    "    push!(Xs, X)\n",
    "    push!(Ys, Y)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Error 0.24687904044075687 0.2482803206620119\n",
      "ADIR 0.24531546274425187 0.2469402857630785\n",
      "ADOS 0.2539418299751587 0.2542911453457032\n",
      "2\n",
      "Error 0.76132803805968165 0.21755365916731317\n",
      "ADIR 0.21301397197965977 0.21609330626237327\n",
      "ADOS 0.22026376621584323 0.22410417907907057\n",
      "3\n",
      "Error 0.1979208194776018 0.2030359451771399\n",
      "ADIR 0.19499189407494114 0.20001517997760954\n",
      "ADOS 0.21115097985095224 0.21658580872130961\n",
      "4\n",
      "Error 0.13291068231953936 0.19581587794155675\n",
      "ADIR 0.18555312197459953 0.1915080675256004\n",
      "ADOS 0.2095940863924924 0.21513887706755186\n",
      "5\n",
      "Error 0.1805927517131078 0.1878872510990432\n",
      "ADIR 0.17588425235491922 0.18320967976572233\n",
      "ADOS 0.20186137179133315 0.2088688399012682\n",
      "6\n",
      "Error 0.4933604116148943 0.18232221360227566\n",
      "ADIR 0.1672799417977395 0.17671391434697634\n",
      "ADOS 0.20082631796853437 0.20747865066530485\n",
      "7\n",
      "Error 0.16579115640834424 0.1756452029997414\n",
      "ADIR 0.15958074513405807 0.1694338500850711\n",
      "ADOS 0.19384401738890422 0.2035066814196953\n",
      "8\n",
      "Error 0.81375893294060445 0.16966640806826996\n",
      "ADIR 0.15164285809761863 0.16312150939577363\n",
      "ADOS 0.190902739442451 0.19902403041393593\n",
      "9\n",
      "Error 0.15230126307988875 0.16443754848719938\n",
      "ADIR 0.14399712807743498 0.15685344364117063\n",
      "ADOS 0.18981162020425063 0.1984566062359917\n",
      "10\n",
      "Error 0.24183010567096136 0.16006206361520559\n",
      "ADIR 0.13734244048494246 0.15117992700960767\n",
      "ADOS 0.18968655120066244 0.1999035378897495\n",
      "11\n",
      "Error 0.1402403275659095 0.15472459270752523\n",
      "ADIR 0.13163296676857153 0.14636660910925156\n",
      "ADOS 0.1791203767595915 0.19221494027860528\n",
      "12\n",
      "Error 0.6713003453575287 0.14853891905870184\n",
      "ADIR 0.12276514203986702 0.13885252019253272\n",
      "ADOS 0.18088859370687277 0.1919879706074276\n",
      "13\n",
      "Error 0.12876098100924446 0.1443496250323248\n",
      "ADIR 0.1176953585224875 0.13377987767468044\n",
      "ADOS 0.17874516974882693 0.1917610009362499\n",
      "14\n",
      "Error 0.94282627218675884 0.14048099301784328\n",
      "ADIR 0.11118388515364977 0.12955478390669373\n",
      "ADOS 0.17541574661882417 0.189491304224473\n",
      "15\n",
      "Error 0.11718626637086928 0.13507111455908974\n",
      "ADIR 0.10455115707545098 0.12308431845063028\n",
      "ADOS 0.17425993651669885 0.18883876641983716\n"
     ]
    }
   ],
   "source": [
    "for l=1:15\n",
    "    println(l)\n",
    "    approx = Xs[l].'*Ys[l]\n",
    "    approx[approx.>0] = 1\n",
    "    approx[approx.<0] = -1\n",
    "    approx = trunc(Int, approx)\n",
    "\n",
    "    adir_train_confusion = zeros(Int, 3, 3)\n",
    "    adir_test_confusion = zeros(Int, 3, 3)\n",
    "    ados_train_confusion = zeros(Int, 3, 3)\n",
    "    ados_test_confusion = zeros(Int, 3, 3)\n",
    "\n",
    "    for i=1:m\n",
    "        for j=adir_indices\n",
    "            if train_data[i, j] != 0\n",
    "                adir_train_confusion[train_data[i, j]+2, approx[i, j]+2] += 1\n",
    "            end\n",
    "            if test_data[i, j] != 0\n",
    "                adir_test_confusion[test_data[i, j]+2, approx[i, j]+2] += 1\n",
    "            end\n",
    "        end\n",
    "        for j=ados_indices\n",
    "            if train_data[i, j] != 0\n",
    "                ados_train_confusion[train_data[i, j]+2, approx[i, j]+2] += 1\n",
    "            end\n",
    "            if test_data[i, j] != 0\n",
    "                ados_test_confusion[test_data[i, j]+2, approx[i, j]+2] += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    println(\"Error \", (adir_train_confusion[1, 3]+adir_train_confusion[3, 1]+ados_train_confusion[1, 3]+ados_train_confusion[3, 1])/(sum(adir_train_confusion)+sum(ados_train_confusion)), \" \", \n",
    "                    (adir_test_confusion[1, 3]+adir_test_confusion[3, 1]+ados_test_confusion[1, 3]+ados_test_confusion[3, 1])/(sum(adir_test_confusion)+sum(ados_test_confusion)))\n",
    "\n",
    "    println(\"ADIR \", (adir_train_confusion[1, 3]+adir_train_confusion[3, 1])/sum(adir_train_confusion), \" \", \n",
    "                    (adir_test_confusion[1, 3]+adir_test_confusion[3, 1])/sum(adir_test_confusion))\n",
    "\n",
    "    println(\"ADOS \", (ados_train_confusion[1, 3]+ados_train_confusion[3, 1])/sum(ados_train_confusion), \" \", \n",
    "                    (ados_test_confusion[1, 3]+ados_test_confusion[3, 1])/sum(ados_test_confusion))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(DataFrame(adir_train_confusion))\n",
    "println(DataFrame(adir_test_confusion))\n",
    "println(DataFrame(ados_train_confusion))\n",
    "println(DataFrame(ados_test_confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed = copy(approx)\n",
    "imputed[imputed.<0] = 0\n",
    "new_df = convert(DataFrame, imputed)\n",
    "names!(new_df, names(df))\n",
    "new_df = hcat(samples, new_df)\n",
    "\n",
    "writecsv(\"../data/impute_logloss_X$(k).csv\", X)\n",
    "writecsv(\"../data/impute_logloss_Y$(k).csv\", Y)\n",
    "writetable(\"../data/impute_logloss_Z$(k).csv\", new_df, separator = ',', header = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# One Instrument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 360112.2038498597\n",
      "Iteration 20: objective value = 334810.3632918745\n",
      "Iteration 30: objective value = 325426.56920161523\n",
      "obj went up to 320702.56769596244; reducing step size to 4.469834102936292\n",
      "Iteration 40: objective value = 319526.5349309807\n",
      "obj went up to 319736.5653291172; reducing step size to 2.979889401957528\n",
      "obj went up to 319043.70318705327; reducing step size to 2.299729645960723\n",
      "Iteration 50: objective value = 317713.9403050886\n",
      "obj went up to 317619.8104115932; reducing step size to 2.1573003712176284\n",
      "Iteration 60: objective value = 316177.78639075166\n",
      "obj went up to 316205.7111956746; reducing step size to 2.0236921760912074\n",
      "obj went up to 314972.267280699; reducing step size to 1.9932766814128595\n",
      "Iteration 70: objective value = 314937.87885173946\n",
      "obj went up to 313921.5257084878; reducing step size to 1.963318322620818\n",
      "Iteration 80: objective value = 313591.7913482437\n",
      "obj went up to 312959.65306189633; reducing step size to 1.9338102290979595\n",
      "Iteration 90: objective value = 312500.4554819803\n",
      "obj went up to 312084.2071265197; reducing step size to 1.9047456334905037\n",
      "Iteration 100: objective value = 311542.6301847533\n"
     ]
    }
   ],
   "source": [
    "using LowRankModels\n",
    "\n",
    "losses = LogisticLoss()\n",
    "rx = ZeroReg()\n",
    "ry = ZeroReg()\n",
    "adir_k = 10\n",
    "adir_glrm = GLRM(train_data[:, adir_indices], losses, rx, ry, adir_k, offset=false, scale=false);\n",
    "init_svd!(adir_glrm);\n",
    "\n",
    "adir_X,adir_Y,adir_ch = fit!(adir_glrm, verbose=true, max_iter=1000); # fit GLRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 82562.5832533424\n",
      "obj went up to 82787.71324869443; reducing step size to 1.0859297511849613\n",
      "obj went up to 77789.04929535909; reducing step size to 0.923968079738386\n",
      "Iteration 20: objective value = 76113.58043898537\n",
      "obj went up to 75316.501524221; reducing step size to 0.9100811128645369\n",
      "Iteration 30: objective value = 74344.20534469547\n",
      "obj went up to 74156.07307360631; reducing step size to 0.8964028629942123\n",
      "Iteration 40: objective value = 73359.78794341543\n",
      "obj went up to 73285.52201762024; reducing step size to 0.8408858982596193\n",
      "Iteration 50: objective value = 72694.17986696522\n",
      "obj went up to 72704.66986005065; reducing step size to 0.8696600135923916\n",
      "Iteration 60: objective value = 72237.5952119492\n",
      "obj went up to 72247.19610319774; reducing step size to 0.81579931512873\n",
      "Iteration 70: objective value = 71846.71539802798\n",
      "obj went up to 71875.46187666628; reducing step size to 0.843714997423432\n",
      "obj went up to 71563.2248886549; reducing step size to 0.7914611529839523\n",
      "Iteration 80: objective value = 71489.87308517778\n",
      "obj went up to 71284.82003713139; reducing step size to 0.818544012316596\n",
      "Iteration 90: objective value = 71213.35406662345\n",
      "obj went up to 71073.63986777233; reducing step size to 0.8062415379853975\n",
      "Iteration 100: objective value = 70963.36638089285\n"
     ]
    }
   ],
   "source": [
    "losses = LogisticLoss()\n",
    "rx = ZeroReg()\n",
    "ry = ZeroReg()\n",
    "ados_k = 4\n",
    "ados_glrm = GLRM(train_data[:, ados_indices], losses, rx, ry, ados_k, offset=false, scale=false);\n",
    "init_svd!(ados_glrm);\n",
    "\n",
    "ados_X,ados_Y,ados_ch = fit!(ados_glrm, verbose=true, max_iter=1000); # fit GLRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADIR 0.1312128717125175 0.14551273536871534\n",
      "ADOS 0.14272960943969087 0.17232672284166028\n"
     ]
    }
   ],
   "source": [
    "adir_approx = adir_X.'*adir_Y\n",
    "adir_approx[adir_approx.>0] = 1\n",
    "adir_approx[adir_approx.<=0] = -1\n",
    "adir_approx = trunc(Int, adir_approx)\n",
    "\n",
    "ados_approx = ados_X.'*ados_Y\n",
    "ados_approx[ados_approx.>0] = 1\n",
    "ados_approx[ados_approx.<=0] = -1\n",
    "ados_approx = trunc(Int, ados_approx)\n",
    "\n",
    "adir_train_confusion = zeros(Int, 3, 3)\n",
    "adir_test_confusion = zeros(Int, 3, 3)\n",
    "ados_train_confusion = zeros(Int, 3, 3)\n",
    "ados_test_confusion = zeros(Int, 3, 3)\n",
    "\n",
    "for i=1:m\n",
    "    for j=adir_indices\n",
    "        if train_data[i, j] != 0\n",
    "            adir_train_confusion[train_data[i, j]+2, adir_approx[i, j]+2] += 1\n",
    "        end\n",
    "        if test_data[i, j] != 0\n",
    "            adir_test_confusion[test_data[i, j]+2, adir_approx[i, j]+2] += 1\n",
    "        end\n",
    "    end\n",
    "    for j=ados_indices\n",
    "        if train_data[i, j] != 0\n",
    "            ados_train_confusion[train_data[i, j]+2, ados_approx[i, j-139]+2] += 1\n",
    "        end\n",
    "        if test_data[i, j] != 0\n",
    "            ados_test_confusion[test_data[i, j]+2, ados_approx[i, j-139]+2] += 1\n",
    "        end\n",
    "    end\n",
    "end\n",
    "println(\"ADIR \", (adir_train_confusion[1, 3]+adir_train_confusion[3, 1])/sum(adir_train_confusion), \" \", \n",
    "                (adir_test_confusion[1, 3]+adir_test_confusion[3, 1])/sum(adir_test_confusion))\n",
    "\n",
    "println(\"ADOS \", (ados_train_confusion[1, 3]+ados_train_confusion[3, 1])/sum(ados_train_confusion), \" \", \n",
    "                (ados_test_confusion[1, 3]+ados_test_confusion[3, 1])/sum(ados_test_confusion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3×3 DataFrames.DataFrame\n",
      "│ Row │ x1     │ x2 │ x3     │\n",
      "├─────┼────────┼────┼────────┤\n",
      "│ 1   │ 397163 │ 0  │ 73446  │\n",
      "│ 2   │ 0      │ 0  │ 0      │\n",
      "│ 3   │ 63984  │ 0  │ 512789 │\n",
      "3×3 DataFrames.DataFrame\n",
      "│ Row │ x1    │ x2 │ x3    │\n",
      "├─────┼───────┼────┼───────┤\n",
      "│ 1   │ 59014 │ 0  │ 12251 │\n",
      "│ 2   │ 0     │ 0  │ 0     │\n",
      "│ 3   │ 10755 │ 0  │ 76083 │\n",
      "3×3 DataFrames.DataFrame\n",
      "│ Row │ x1    │ x2 │ x3     │\n",
      "├─────┼───────┼────┼────────┤\n",
      "│ 1   │ 67694 │ 0  │ 19723  │\n",
      "│ 2   │ 0     │ 0  │ 0      │\n",
      "│ 3   │ 13372 │ 0  │ 131083 │\n",
      "3×3 DataFrames.DataFrame\n",
      "│ Row │ x1   │ x2 │ x3    │\n",
      "├─────┼──────┼────┼───────┤\n",
      "│ 1   │ 9833 │ 0  │ 3535  │\n",
      "│ 2   │ 0    │ 0  │ 0     │\n",
      "│ 3   │ 2539 │ 0  │ 19340 │\n"
     ]
    }
   ],
   "source": [
    "println(DataFrame(adir_train_confusion))\n",
    "println(DataFrame(adir_test_confusion))\n",
    "println(DataFrame(ados_train_confusion))\n",
    "println(DataFrame(ados_test_confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
