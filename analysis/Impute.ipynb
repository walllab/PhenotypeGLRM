{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13434,123)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames\n",
    "\n",
    "# To run this notebook, you need to have a data file available.\n",
    "# You can either run the phenotype preprocessing scripts in ../preprocessing directory\n",
    "# Or scp -r username@sherlock.stanford.edu:/scratch/PI/dpwall/DATA/phenotypes/jsonschema ../data\n",
    "\n",
    "# Data\n",
    "df = readtable(\"../data/all_samples_filtered.csv\", nastrings=[\"None\", \"\"])\n",
    "samples = df[:, 1:1]\n",
    "df = df[:, 2:end] # Remove identifier\n",
    "\n",
    "# Binarize Data\n",
    "[df[df[nm].> 2, nm] = 3 for nm in names(df)]\n",
    "[df[df[nm].== 2, nm] = 3 for nm in names(df)]\n",
    "[df[df[nm].== 1, nm] = 2 for nm in names(df)]\n",
    "[df[df[nm].== 0, nm] = 1 for nm in names(df)]\n",
    "[df[isna(df[nm]), nm] = 0 for nm in names(df)]\n",
    "\n",
    "m, n = size(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001073"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Form sparse array\n",
    "all_data = sparse(Array(df))\n",
    "dropzeros!(all_data)\n",
    "p = size(nonzeros(all_data), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78:123"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adir_indices = 1:77\n",
    "ados_indices = 78:n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94998,) (94998,)\n",
      "(47498,) (47498,)\n",
      "(807477,) (807477,)\n"
     ]
    }
   ],
   "source": [
    "# First split out whole instrument test data\n",
    "all_sample_indices = collect(1:m)\n",
    "break1, break2 = ceil(Integer, 0.05 * m), ceil(Integer, 0.1 * m)\n",
    "adir_heldout_indices = view(all_sample_indices, 1:(break1-1))\n",
    "ados_heldout_indices = view(all_sample_indices, break1:(break2-1))\n",
    "\n",
    "remaining_data = copy(all_data)\n",
    "remaining_data[adir_heldout_indices, adir_indices] = 0\n",
    "remaining_data[ados_heldout_indices, ados_indices] = 0\n",
    "dropzeros!(remaining_data)\n",
    "p = size(nonzeros(remaining_data), 1)\n",
    "\n",
    "# Split out testing data\n",
    "all_indices = collect(1:p)\n",
    "shuffle!(all_indices)\n",
    "break1, break2 = ceil(Integer, 0.85 * p), ceil(Integer, 0.9 * p)\n",
    "train_indices = view(all_indices, 1:(break1-1))\n",
    "test_indices = view(all_indices, break1:(break2-1))\n",
    "held_out_test_indices = view(all_indices, break2:p)\n",
    "\n",
    "train_data = copy(remaining_data)\n",
    "nonzeros(train_data)[union(test_indices, held_out_test_indices)] = 0\n",
    "dropzeros!(train_data)\n",
    "\n",
    "test_data = copy(remaining_data)\n",
    "nonzeros(test_data)[union(train_indices, held_out_test_indices)] = 0\n",
    "dropzeros!(test_data)\n",
    "\n",
    "heldout_data = copy(remaining_data)\n",
    "nonzeros(heldout_data)[union(train_indices, test_indices)] = 0\n",
    "dropzeros!(heldout_data)\n",
    "\n",
    "println(size(held_out_test_indices), \" \", size(nonzeros(heldout_data)))\n",
    "println(size(test_indices), \" \", size(nonzeros(test_data)))\n",
    "println(size(train_indices), \" \", size(nonzeros(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65030,)\n",
      "(29968,)\n"
     ]
    }
   ],
   "source": [
    "println(size(nonzeros(heldout_data[:, adir_indices])))\n",
    "println(size(nonzeros(heldout_data[:, ados_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GLRM\n",
      "Iteration 10: objective value = 534301.9627493373\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      " in get_yidxs(::Array{LowRankModels.Loss,1}) at /Users/kelley/.julia/v0.5/LowRankModels/src/losses.jl:81",
      " in row_objective(::LowRankModels.GLRM, ::Int64, ::ArrayViews.ContiguousView{Float64,1,Array{Float64,2}}, ::Array{Float64,2}) at /Users/kelley/.julia/v0.5/LowRankModels/src/evaluate_fit.jl:27 (repeats 2 times)",
      " in #fit!#62(::LowRankModels.ConvergenceHistory, ::Bool, ::Array{Any,1}, ::Function, ::LowRankModels.GLRM, ::LowRankModels.ProxGradParams) at /Users/kelley/.julia/v0.5/LowRankModels/src/algorithms/proxgrad.jl:138",
      " in (::StatsBase.#kw##fit!)(::Array{Any,1}, ::StatsBase.#fit!, ::LowRankModels.GLRM, ::LowRankModels.ProxGradParams) at ./<missing>:0",
      " in macro expansion; at ./In[455]:13 [inlined]",
      " in anonymous at ./<missing>:?",
      " in include_string(::String, ::String) at ./loading.jl:441",
      " in include_string(::String, ::String) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?"
     ]
    }
   ],
   "source": [
    "using LowRankModels\n",
    "\n",
    "Xs = []\n",
    "Ys = []\n",
    "for k=6:6\n",
    "    losses = [MultinomialLoss(3) for i=1:n]\n",
    "\n",
    "    rx = ZeroReg()\n",
    "    ry = ZeroReg()\n",
    "    glrm = GLRM(train_data, losses, rx, ry, k, offset=false, scale=false);\n",
    "    init_svd!(glrm);\n",
    "\n",
    "    X,Y,ch = fit!(glrm, ProxGradParams(), verbose=true, max_iter=5000); # fit GLRM\n",
    "    push!(Xs, X)\n",
    "    push!(Ys, Y)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching sort_observations(::Array{Tuple{Any,Any},1}, ::Int64, ::Int64)\u001b[0m\nClosest candidates are:\n  sort_observations(\u001b[1m\u001b[31m::Array{Tuple{Int64,Int64},1}\u001b[0m, ::Int64, ::Int64; check_empty) at /Users/kelley/.julia/v0.5/LowRankModels/src/modify_glrm.jl:6\u001b[0m",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching sort_observations(::Array{Tuple{Any,Any},1}, ::Int64, ::Int64)\u001b[0m\nClosest candidates are:\n  sort_observations(\u001b[1m\u001b[31m::Array{Tuple{Int64,Int64},1}\u001b[0m, ::Int64, ::Int64; check_empty) at /Users/kelley/.julia/v0.5/LowRankModels/src/modify_glrm.jl:6\u001b[0m",
      "",
      " in #GLRM#32(::Array{Float64,2}, ::Array{Float64,2}, ::Void, ::Array{UnitRange{Int64},1}, ::Array{UnitRange{Int64},1}, ::Bool, ::Bool, ::Bool, ::Bool, ::Type{T}, ::SparseMatrixCSC{Int64,Int64}, ::Array{LowRankModels.LogisticLoss,1}, ::LowRankModels.ZeroReg, ::Array{LowRankModels.Regularizer,1}, ::Int64) at /Users/kelley/.julia/v0.5/LowRankModels/src/glrm.jl:58",
      " in (::Core.#kw#Type)(::Array{Any,1}, ::Type{LowRankModels.GLRM}, ::SparseMatrixCSC{Int64,Int64}, ::Array{LowRankModels.LogisticLoss,1}, ::LowRankModels.ZeroReg, ::Array{LowRankModels.Regularizer,1}, ::Int64) at ./<missing>:0",
      " in #GLRM#152(::Array{Any,1}, ::Type{T}, ::SparseMatrixCSC{Int64,Int64}, ::LowRankModels.LogisticLoss, ::LowRankModels.ZeroReg, ::LowRankModels.ZeroReg, ::Int64) at /Users/kelley/.julia/v0.5/LowRankModels/src/utilities/conveniencemethods.jl:57",
      " in (::Core.#kw#Type)(::Array{Any,1}, ::Type{LowRankModels.GLRM}, ::SparseMatrixCSC{Int64,Int64}, ::LowRankModels.LogisticLoss, ::LowRankModels.ZeroReg, ::LowRankModels.ZeroReg, ::Int64) at ./<missing>:0",
      " in include_string(::String, ::String) at ./loading.jl:441",
      " in include_string(::String, ::String) at /Applications/Julia-0.5.app/Contents/Resources/julia/lib/julia/sys.dylib:?"
     ]
    }
   ],
   "source": [
    "using LowRankModels\n",
    "\n",
    "k = 5\n",
    "losses = LogisticLoss()\n",
    "rx = ZeroReg()\n",
    "ry = ZeroReg()\n",
    "glrm = GLRM(train_data, losses, rx, ry, k, offset=false, scale=false);\n",
    "init_svd!(glrm);\n",
    "\n",
    "X,Y,ch = fit!(glrm, verbose=true, max_iter=5000); # fit GLRM\n",
    "push!(Xs, X)\n",
    "push!(Ys, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 345058.04418069025\n",
      "Iteration 20: objective value = 260530.07672721613\n",
      "obj went up to 253953.30022975296; reducing step size to 2.744090396921059\n",
      "Iteration 30: objective value = 253453.74653149213\n",
      "obj went up to 253506.13483629696; reducing step size to 1.8293935979473728\n",
      "obj went up to 253186.70614302575; reducing step size to 1.5565475464105132\n",
      "Iteration 40: objective value = 253056.75860194003\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 236610.52202479122\n",
      "Iteration 20: objective value = 222986.85860227654\n",
      "obj went up to 222391.32098451263; reducing step size to 2.150066629142469\n",
      "obj went up to 221475.34472904255; reducing step size to 1.5802989724197147\n",
      "Iteration 30: objective value = 221015.046145284\n",
      "obj went up to 220722.69214762896; reducing step size to 1.4118345092158846\n",
      "Iteration 40: objective value = 220262.861039521\n",
      "obj went up to 220163.18334584442; reducing step size to 1.3906150542468458\n",
      "Iteration 50: objective value = 219808.05405139067\n",
      "obj went up to 219803.5043056727; reducing step size to 1.369714521408017\n",
      "Iteration 60: objective value = 219516.31938905077\n",
      "obj went up to 219523.88024060003; reducing step size to 1.3491281173941372\n",
      "obj went up to 219305.83056926384; reducing step size to 1.2053071391763313\n",
      "Iteration 70: objective value = 219267.09396623488\n",
      "obj went up to 219138.6449755388; reducing step size to 1.1871917294759282\n",
      "Iteration 80: objective value = 219093.5236021495\n",
      "obj went up to 218998.71508887946; reducing step size to 1.2892068193986386\n",
      "Iteration 90: objective value = 218956.53697740592\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 229715.28466774352\n",
      "Iteration 20: objective value = 210458.13855372442\n",
      "obj went up to 208871.06021742977; reducing step size to 2.150066629142469\n",
      "obj went up to 208060.2841928769; reducing step size to 1.7422796170927357\n",
      "Iteration 30: objective value = 207803.58484860515\n",
      "obj went up to 206952.26235380015; reducing step size to 1.4118345092158846\n",
      "Iteration 40: objective value = 206155.3003957153\n",
      "obj went up to 205988.29804112253; reducing step size to 1.3906150542468458\n",
      "Iteration 50: objective value = 205375.72499505078\n",
      "obj went up to 205336.0388072878; reducing step size to 1.369714521408017\n",
      "Iteration 60: objective value = 204815.20195327234\n",
      "obj went up to 204820.56571730765; reducing step size to 1.3491281173941372\n",
      "Iteration 70: objective value = 204369.7194629749\n",
      "obj went up to 204401.42658623896; reducing step size to 1.3288511209419054\n",
      "obj went up to 204056.01279918032; reducing step size to 1.308878881747211\n",
      "Iteration 80: objective value = 204026.28165839732\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 213897.2536384738\n",
      "Iteration 20: objective value = 199808.84322665495\n",
      "obj went up to 198800.5508415299; reducing step size to 2.150066629142469\n",
      "obj went up to 197697.93052974262; reducing step size to 1.5802989724197147\n",
      "Iteration 30: objective value = 197078.15839828452\n",
      "obj went up to 196640.8641541049; reducing step size to 1.4118345092158846\n",
      "Iteration 40: objective value = 195807.85893315056\n",
      "obj went up to 195616.1798728537; reducing step size to 1.3906150542468458\n",
      "Iteration 50: objective value = 194858.98341927698\n",
      "obj went up to 194797.1855701755; reducing step size to 1.369714521408017\n",
      "Iteration 60: objective value = 194120.75190569455\n",
      "obj went up to 194101.7161053029; reducing step size to 1.3491281173941372\n",
      "Iteration 70: objective value = 193466.05310602963\n",
      "obj went up to 193498.36403400128; reducing step size to 1.3288511209419054\n",
      "obj went up to 192966.95241478254; reducing step size to 1.308878881747211\n",
      "Iteration 80: objective value = 192940.12317342943\n",
      "obj went up to 192493.17061641524; reducing step size to 1.2892068193986388\n",
      "Iteration 90: objective value = 192363.90559314282\n",
      "obj went up to 192071.99521477593; reducing step size to 1.2698304223270014\n",
      "Iteration 100: objective value = 191898.79539351785\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 210085.7888414302\n",
      "Iteration 20: objective value = 193834.4789192911\n",
      "obj went up to 191958.07502663284; reducing step size to 2.370448458629572\n",
      "obj went up to 190818.13343572197; reducing step size to 1.7422796170927357\n",
      "Iteration 30: objective value = 190569.99469875096\n",
      "obj went up to 189433.75881856808; reducing step size to 1.5565475464105127\n",
      "Iteration 40: objective value = 188305.7402323031\n",
      "obj went up to 187967.29826026724; reducing step size to 1.5331530973071477\n",
      "Iteration 50: objective value = 186961.5801028633\n",
      "obj went up to 186813.12875233608; reducing step size to 1.510110259852339\n",
      "Iteration 60: objective value = 185834.66521587918\n",
      "obj went up to 185779.6460705366; reducing step size to 1.4874137494270367\n",
      "Iteration 70: objective value = 184810.17899385781\n",
      "obj went up to 184842.6485262498; reducing step size to 1.4650583608384513\n",
      "Iteration 80: objective value = 183956.45353022704\n",
      "obj went up to 183994.40623305397; reducing step size to 1.4430389671263006\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 188890.5199266847\n",
      "Iteration 20: objective value = 179256.90305359758\n",
      "obj went up to 178177.222126765; reducing step size to 2.150066629142469\n",
      "obj went up to 177658.1043703577; reducing step size to 1.7422796170927357\n",
      "Iteration 30: objective value = 177370.5821572503\n",
      "obj went up to 176445.44793034016; reducing step size to 1.4118345092158846\n",
      "Iteration 40: objective value = 175613.86682929957\n",
      "obj went up to 175465.4078844178; reducing step size to 1.5331530973071477\n",
      "Iteration 50: objective value = 174683.1840394392\n",
      "obj went up to 174634.94730942708; reducing step size to 1.369714521408017\n",
      "Iteration 60: objective value = 173922.68679306124\n",
      "obj went up to 173877.56328238646; reducing step size to 1.3491281173941372\n",
      "Iteration 70: objective value = 173283.39975149845\n",
      "obj went up to 173359.73078276965; reducing step size to 1.4650583608384506\n",
      "obj went up to 172775.35689516418; reducing step size to 1.308878881747211\n",
      "Iteration 80: objective value = 172748.0059419772\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 182035.76957859212\n",
      "Iteration 20: objective value = 170263.53873258614\n",
      "obj went up to 169301.20485370385; reducing step size to 2.370448458629572\n",
      "obj went up to 168010.618343439; reducing step size to 1.7422796170927357\n",
      "Iteration 30: objective value = 167831.5716514704\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 176527.39092952543\n",
      "Iteration 20: objective value = 162159.8181520849\n",
      "obj went up to 160203.28799813706; reducing step size to 2.370448458629572\n",
      "obj went up to 158976.695205117; reducing step size to 1.7422796170927357\n",
      "Iteration 30: objective value = 158905.07868730064\n",
      "obj went up to 157483.798404547; reducing step size to 1.5565475464105127\n",
      "Iteration 40: objective value = 156577.59433364245\n",
      "obj went up to 156132.26925913536; reducing step size to 1.5331530973071477\n",
      "Iteration 50: objective value = 155259.9236138235\n",
      "obj went up to 155069.6110729179; reducing step size to 1.510110259852339\n",
      "Iteration 60: objective value = 154197.2837392368\n",
      "obj went up to 154154.39340469395; reducing step size to 1.4874137494270367\n",
      "Iteration 70: objective value = 153297.57049717114\n",
      "obj went up to 153286.8732193119; reducing step size to 1.3952936769890012\n",
      "Iteration 80: objective value = 152555.0476631141\n",
      "obj went up to 152555.48684320657; reducing step size to 1.3743228258345719\n",
      "obj went up to 151921.2382408343; reducing step size to 1.3536671603685713\n",
      "Iteration 90: objective value = 151920.42211506504\n",
      "obj went up to 151346.13913500946; reducing step size to 1.3333219434433519\n",
      "Iteration 100: objective value = 151146.89681362564\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 167632.3805559593\n",
      "Iteration 20: objective value = 153076.87678719132\n",
      "obj went up to 150911.70319260046; reducing step size to 2.370448458629572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj went up to 149796.14913013682; reducing step size to 1.7422796170927357\n",
      "Iteration 30: objective value = 149681.96681952628\n",
      "obj went up to 148293.24399742758; reducing step size to 1.5565475464105127\n",
      "Iteration 40: objective value = 147322.75004107875\n",
      "obj went up to 146918.8584407962; reducing step size to 1.5331530973071477\n",
      "Iteration 50: objective value = 145981.09889475923\n",
      "obj went up to 145847.85194900644; reducing step size to 1.510110259852339\n",
      "Iteration 60: objective value = 144903.78183171878\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 158490.6486418879\n",
      "Iteration 20: objective value = 143992.7787962751\n",
      "obj went up to 140959.28231616243; reducing step size to 2.370448458629572\n",
      "Iteration 30: objective value = 139766.72548253505\n",
      "obj went up to 140075.12365371245; reducing step size to 1.8293935979473723\n",
      "obj went up to 138194.61750263488; reducing step size to 1.6343749237310385\n",
      "Iteration 40: objective value = 137144.38676480472\n",
      "obj went up to 136441.12055216832; reducing step size to 1.5331530973071477\n",
      "Iteration 50: objective value = 135592.15787513618\n",
      "obj went up to 135239.41274885082; reducing step size to 1.585615772844956\n",
      "Iteration 60: objective value = 134351.12887591758\n",
      "obj went up to 134199.5482594511; reducing step size to 1.4874137494270367\n",
      "Iteration 70: objective value = 133338.75335457223\n",
      "obj went up to 133278.9223140028; reducing step size to 1.4650583608384513\n",
      "Iteration 80: objective value = 132502.6728054333\n",
      "obj went up to 132502.35284290282; reducing step size to 1.4430389671263006\n",
      "Iteration 90: objective value = 131782.12915541933\n",
      "obj went up to 131804.51509322305; reducing step size to 1.4213505183869997\n",
      "obj went up to 131170.0648466582; reducing step size to 1.3999880406155194\n",
      "Iteration 100: objective value = 131150.31557023525\n"
     ]
    }
   ],
   "source": [
    "using LowRankModels\n",
    "\n",
    "adir_Xs = []\n",
    "adir_Ys = []\n",
    "for k=1:10\n",
    "    losses = LogisticLoss()\n",
    "    rx = ZeroReg()\n",
    "    ry = ZeroReg()\n",
    "    glrm = GLRM(train_data[:, adir_indices], losses, rx, ry, k, offset=false, scale=false);\n",
    "    init_svd!(glrm);\n",
    "\n",
    "    X,Y,ch = fit!(glrm, verbose=true, max_iter=1000); # fit GLRM\n",
    "    push!(adir_Xs, X)\n",
    "    push!(adir_Ys, Y)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "obj went up to 154774.06955478943; reducing step size to 0.7000000000000001\n",
      "obj went up to 145226.50338865927; reducing step size to 0.5402250000000001\n",
      "Iteration 10: objective value = 141177.8598754878\n",
      "obj went up to 139566.18198886505; reducing step size to 0.5866463998338959\n",
      "Iteration 20: objective value = 138021.9940893037\n",
      "obj went up to 137223.60531795898; reducing step size to 0.5778292780092299\n",
      "Iteration 30: objective value = 135424.66135644974\n",
      "obj went up to 134794.2103629715; reducing step size to 0.5691446749169604\n",
      "Iteration 40: objective value = 133184.82325681017\n",
      "obj went up to 132751.64673217057; reducing step size to 0.5886201287817338\n",
      "Iteration 50: objective value = 131211.7616839303\n",
      "obj went up to 130985.96668364444; reducing step size to 0.579773342394928\n",
      "Iteration 60: objective value = 129437.27267851081\n",
      "obj went up to 129290.15535486647; reducing step size to 0.571059520590111\n",
      "Iteration 70: objective value = 127889.02197475733\n",
      "obj went up to 127912.985782063; reducing step size to 0.5906004981964025\n",
      "Iteration 80: objective value = 126611.93733450724\n",
      "obj went up to 126753.66332008733; reducing step size to 0.581723947443205\n",
      "Iteration 90: objective value = 125467.70625605843\n",
      "obj went up to 125593.6713104937; reducing step size to 0.5729808086216174\n",
      "obj went up to 124560.64793738595; reducing step size to 0.5643690765897785\n",
      "Iteration 100: objective value = 124471.04541651822\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "obj went up to 133933.79962796337; reducing step size to 0.735\n",
      "obj went up to 120178.14538029519; reducing step size to 0.6566468639062502\n",
      "Iteration 10: objective value = 119846.85087917875\n",
      "obj went up to 112158.01229213896; reducing step size to 0.6467776558168702\n",
      "Iteration 20: objective value = 110174.62756689399\n",
      "obj went up to 107879.28707167647; reducing step size to 0.6067207419096913\n",
      "Iteration 30: objective value = 106348.33872148825\n",
      "obj went up to 105280.24782849532; reducing step size to 0.5976019086628083\n",
      "Iteration 40: objective value = 104188.14282192707\n",
      "obj went up to 103675.99877452046; reducing step size to 0.5886201287817336\n",
      "Iteration 50: objective value = 102786.98939445331\n",
      "obj went up to 102558.988472022; reducing step size to 0.5797733423949278\n",
      "Iteration 60: objective value = 101822.47146628474\n",
      "obj went up to 101735.57852844454; reducing step size to 0.5710595205901109\n",
      "Iteration 70: objective value = 101126.19951829918\n",
      "obj went up to 101102.50034550641; reducing step size to 0.5624766649489547\n",
      "Iteration 80: objective value = 100602.64432602594\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "obj went up to 126840.63367358346; reducing step size to 0.735\n",
      "Iteration 10: objective value = 113866.77627661663\n",
      "obj went up to 114327.85150585134; reducing step size to 0.6894792071015626\n",
      "obj went up to 106182.12848349453; reducing step size to 0.6159787198255906\n",
      "Iteration 20: objective value = 104203.65076431078\n",
      "obj went up to 101890.70185522358; reducing step size to 0.6370567790051759\n",
      "Iteration 30: objective value = 100372.85923785124\n",
      "obj went up to 99217.972051221; reducing step size to 0.6274820040959487\n",
      "Iteration 40: objective value = 97689.2210290475\n",
      "obj went up to 97131.45688290062; reducing step size to 0.6180511352208203\n",
      "Iteration 50: objective value = 95763.6793719901\n",
      "obj went up to 95511.21638560541; reducing step size to 0.6087620095146743\n",
      "Iteration 60: objective value = 94321.57642980778\n",
      "obj went up to 94215.43261939779; reducing step size to 0.5996124966196165\n",
      "Iteration 70: objective value = 93183.51443473762\n",
      "obj went up to 93149.35475562105; reducing step size to 0.5906004981964024\n",
      "Iteration 80: objective value = 92260.67596561593\n",
      "obj went up to 92255.53837977372; reducing step size to 0.5817239474432049\n",
      "Iteration 90: objective value = 91488.29472364413\n",
      "obj went up to 91496.20718558552; reducing step size to 0.5729808086216173\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "obj went up to 111382.31774453077; reducing step size to 0.77175\n",
      "Iteration 10: objective value = 96226.26658136255\n",
      "obj went up to 96324.79602633318; reducing step size to 0.6894792071015626\n",
      "obj went up to 89287.73398140351; reducing step size to 0.6467776558168702\n",
      "Iteration 20: objective value = 87946.09318304996\n",
      "obj went up to 85937.43320210735; reducing step size to 0.6370567790051759\n",
      "Iteration 30: objective value = 84650.88998586568\n",
      "obj went up to 83802.96133389237; reducing step size to 0.5976019086628083\n",
      "Iteration 40: objective value = 82816.72153289762\n",
      "obj went up to 82388.07580192618; reducing step size to 0.5886201287817336\n",
      "Iteration 50: objective value = 81646.09128728218\n",
      "obj went up to 81446.65151629352; reducing step size to 0.5797733423949278\n",
      "Iteration 60: objective value = 80813.30144124143\n",
      "obj went up to 80733.42253011581; reducing step size to 0.5710595205901109\n",
      "Iteration 70: objective value = 80190.88700261113\n",
      "obj went up to 80168.19631894812; reducing step size to 0.5624766649489547\n",
      "Iteration 80: objective value = 79704.8086914691\n",
      "obj went up to 79705.02671737091; reducing step size to 0.5540228070887666\n",
      "Iteration 90: objective value = 79316.4837784596\n",
      "obj went up to 79341.61259411393; reducing step size to 0.5729808086216174\n",
      "obj went up to 79003.81746106014; reducing step size to 0.5374943586569318\n",
      "Iteration 100: objective value = 78921.8890194572\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "obj went up to 101737.42729879527; reducing step size to 0.77175\n",
      "Iteration 10: objective value = 86479.50491249216\n",
      "obj went up to 86903.83387697341; reducing step size to 0.760150825829473\n",
      "obj went up to 80059.82900756724; reducing step size to 0.6791165386077137\n",
      "Iteration 20: objective value = 79584.4163700071\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "obj went up to 80618.06623216181; reducing step size to 0.9849702958593753\n",
      "Iteration 10: objective value = 70761.12441837692\n",
      "obj went up to 67629.95934605274; reducing step size to 0.7981583671209468\n",
      "Iteration 20: objective value = 63375.9084010665\n",
      "obj went up to 63422.64293559822; reducing step size to 0.7130723655380996\n",
      "obj went up to 61060.30817151798; reducing step size to 0.7023550988532067\n",
      "Iteration 30: objective value = 60958.97183931924\n",
      "obj went up to 59464.38250271296; reducing step size to 0.6588561043007465\n",
      "Iteration 40: objective value = 58826.70232088111\n",
      "obj went up to 58293.94946641024; reducing step size to 0.6489536919818616\n",
      "Iteration 50: objective value = 57704.52850476486\n",
      "obj went up to 57419.5896497822; reducing step size to 0.6392001099904082\n",
      "Iteration 60: objective value = 56832.60489434506\n",
      "obj went up to 56697.00644633612; reducing step size to 0.6295931214505975\n",
      "Iteration 70: objective value = 56130.62121425711\n",
      "obj went up to 56085.105201183214; reducing step size to 0.6201305231062227\n",
      "Iteration 80: objective value = 55547.41082097518\n",
      "obj went up to 55556.351918002765; reducing step size to 0.6108101448153653\n",
      "Iteration 90: objective value = 55064.310146317046\n",
      "obj went up to 55093.032789252284; reducing step size to 0.6016298490526983\n",
      "Iteration 100: objective value = 54653.168993897045\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 72738.6744132327\n",
      "obj went up to 72846.12661008857; reducing step size to 1.0859297511849613\n",
      "obj went up to 60228.48272502289; reducing step size to 0.8799695997508438\n",
      "Iteration 20: objective value = 56118.6071519231\n",
      "obj went up to 55906.536438543684; reducing step size to 0.7861622830057547\n",
      "Iteration 30: objective value = 53188.85880935393\n",
      "obj went up to 53325.83406803498; reducing step size to 0.7743464964856601\n",
      "obj went up to 51371.37914165338; reducing step size to 0.6917989095157834\n",
      "Iteration 40: objective value = 50926.736127948476\n",
      "obj went up to 49981.52512207566; reducing step size to 0.7154714454100022\n",
      "Iteration 50: objective value = 49510.833379348034\n",
      "obj went up to 48915.52556342381; reducing step size to 0.6711601154899284\n",
      "Iteration 60: objective value = 48343.608583943096\n",
      "obj went up to 48003.37627679764; reducing step size to 0.6610727775231272\n",
      "Iteration 70: objective value = 47448.94244920242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj went up to 47252.36787209618; reducing step size to 0.6511370492615337\n",
      "Iteration 80: objective value = 46701.84269422681\n",
      "obj went up to 46603.29934789845; reducing step size to 0.6413506520561335\n",
      "Iteration 90: objective value = 46065.000519914\n",
      "obj went up to 46033.23189383051; reducing step size to 0.6317113415053331\n",
      "Iteration 100: objective value = 45524.69553848929\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 59605.71037915898\n",
      "obj went up to 59569.54955787925; reducing step size to 1.1972375506814201\n",
      "obj went up to 48376.585029221475; reducing step size to 0.9701664837253055\n",
      "Iteration 20: objective value = 45290.49774490954\n",
      "obj went up to 44785.77391221214; reducing step size to 0.8667439170138448\n",
      "Iteration 30: objective value = 42267.15289500295\n",
      "obj went up to 42192.81423541402; reducing step size to 0.7743464964856602\n",
      "Iteration 40: objective value = 40456.896737749\n",
      "obj went up to 40479.48046984066; reducing step size to 0.7627082977411516\n",
      "obj went up to 39224.527705221655; reducing step size to 0.7512450176805027\n",
      "Iteration 50: objective value = 39178.62389289854\n",
      "obj went up to 38202.66169129614; reducing step size to 0.7399540273276465\n",
      "Iteration 60: objective value = 37823.86208876675\n",
      "obj went up to 37347.68142640592; reducing step size to 0.7288327372192481\n",
      "Iteration 70: objective value = 36851.12085085728\n",
      "obj went up to 36545.406677705985; reducing step size to 0.6836939017246108\n",
      "Iteration 80: objective value = 36095.14353712503\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 50111.654767277156\n",
      "obj went up to 49375.59748540897; reducing step size to 1.1972375506814201\n",
      "obj went up to 41474.28823639338; reducing step size to 0.9701664837253055\n",
      "Iteration 20: objective value = 39761.08007033745\n",
      "obj went up to 38078.03624867994; reducing step size to 0.9555851685077639\n",
      "Iteration 30: objective value = 36115.5571460495\n",
      "obj went up to 35618.06496155805; reducing step size to 0.8537170123754403\n",
      "Iteration 40: objective value = 33925.35349717857\n",
      "obj went up to 33785.33231221251; reducing step size to 0.8408858982596193\n",
      "Iteration 50: objective value = 32342.75959492783\n",
      "obj went up to 32371.736183504923; reducing step size to 0.8282476319927539\n",
      "obj went up to 31131.770168546795; reducing step size to 0.7399540273276463\n",
      "Iteration 60: objective value = 30837.151886018142\n",
      "obj went up to 30137.10901248321; reducing step size to 0.728832737219248\n",
      "Iteration 70: objective value = 29763.194062736828\n",
      "obj went up to 29343.93753804955; reducing step size to 0.7178785968108411\n",
      "Iteration 80: objective value = 28910.700866211762\n",
      "obj went up to 28652.68465756786; reducing step size to 0.7070890938918873\n",
      "Iteration 90: objective value = 28184.13275064944\n",
      "obj went up to 28044.01206953787; reducing step size to 0.6964617540096301\n",
      "Iteration 100: objective value = 27565.676157436865\n",
      "LowRankModels.SparseProxGradParams(1.0,100,1,1.0e-5,0.01)\n",
      "Fitting GLRM\n",
      "Iteration 10: objective value = 47595.22965028336\n",
      "obj went up to 46458.73267026923; reducing step size to 1.1972375506814201\n",
      "obj went up to 38223.51028012026; reducing step size to 0.9701664837253055\n",
      "Iteration 20: objective value = 36250.553361401064\n",
      "obj went up to 34000.79728833768; reducing step size to 0.9555851685077639\n",
      "Iteration 30: objective value = 32091.38664470952\n",
      "obj went up to 31133.190664763264; reducing step size to 0.9412230061439231\n",
      "Iteration 40: objective value = 29262.195455237237\n",
      "obj went up to 28930.355668386364; reducing step size to 0.8408858982596196\n",
      "Iteration 50: objective value = 27402.054270320357\n",
      "obj went up to 27190.644685960204; reducing step size to 0.9131430142720114\n",
      "Iteration 60: objective value = 25771.412731140168\n",
      "obj went up to 25816.786434693553; reducing step size to 0.81579931512873\n",
      "obj went up to 24694.199304007238; reducing step size to 0.803538092784221\n",
      "Iteration 70: objective value = 24663.772348954484\n",
      "obj went up to 23781.756567938253; reducing step size to 0.7914611529839523\n",
      "Iteration 80: objective value = 23521.423024865486\n",
      "obj went up to 22999.08889350551; reducing step size to 0.7795657260158056\n",
      "Iteration 90: objective value = 22606.565400267038\n",
      "obj went up to 22315.680776498528; reducing step size to 0.7678490837956167\n",
      "Iteration 100: objective value = 21875.961826811435\n"
     ]
    }
   ],
   "source": [
    "using LowRankModels\n",
    "\n",
    "ados_Xs = []\n",
    "ados_Ys = []\n",
    "for k=1:10\n",
    "    losses = LogisticLoss()\n",
    "    rx = ZeroReg()\n",
    "    ry = ZeroReg()\n",
    "    glrm = GLRM(train_data[:, ados_indices], losses, rx, ry, k, offset=false, scale=false);\n",
    "    init_svd!(glrm);\n",
    "\n",
    "    X,Y,ch = fit!(glrm, verbose=true, max_iter=1000); # fit GLRM\n",
    "    push!(ados_Xs, X)\n",
    "    push!(ados_Ys, Y)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both Instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Error 0.2420465226873335 0.24415764874310497\n",
      "ADIR 0.23155070655716098 0.23138703963842913\n",
      "ADOS 0.2649707800657744 0.2725054229934924\n",
      "2\n",
      "Error 0.6042212397380978 0.21485115162743695\n",
      "ADIR 0.2026167981324576 0.20888047395101692\n",
      "ADOS 0.20135728763298816 0.22810466377440347\n",
      "3\n",
      "Error 0.18611427941600814 0.20775611604699146\n",
      "ADIR 0.18290144308455034 0.19776461247175228\n",
      "ADOS 0.1931315409670576 0.2299349240780911\n",
      "4\n",
      "Error 0.59139995690279722 0.20198745210324645\n",
      "ADIR 0.1696134382170964 0.19251206254198985\n",
      "ADOS 0.17848608405561645 0.22302060737527116\n",
      "5\n",
      "Error 0.16364924326017954 0.20120847193566044\n",
      "ADIR 0.16331246851771944 0.19300067183778172\n",
      "ADOS 0.16438480405687833 0.21942787418655096\n",
      "6\n",
      "Error 0.67373564819802918 0.20287169986104678\n",
      "ADIR 0.15213321224879622 0.19153484395040615\n",
      "ADOS 0.15723558128346884 0.22803687635574837\n",
      "7\n",
      "Error 0.1463880704961256 0.20337698429407555\n",
      "ADIR 0.14856928268244377 0.19275636718988579\n",
      "ADOS 0.14162401318643186 0.2269522776572668\n",
      "8\n",
      "Error 0.77288256507615695 0.20493494462924755\n",
      "ADIR 0.14056939823031217 0.1943748854821963\n",
      "ADOS 0.1320141643729741 0.22837581344902386\n",
      "9\n",
      "Error 0.1285844674213631 0.20537706850814771\n",
      "ADIR 0.13231855825147187 0.19379466194344347\n",
      "ADOS 0.12042871676774687 0.23108731019522777\n",
      "10\n",
      "Error 0.86992976022846472 0.20828245399806308\n",
      "ADIR 0.12425187268791424 0.19645147498931168\n",
      "ADOS 0.11367382509049899 0.23454446854663774\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "adir_error = []\n",
    "ados_error = []\n",
    "for l=1:10\n",
    "    println(l)\n",
    "    approx = Xs[l].'*Ys[l]\n",
    "    approx[approx.>=0] = 1\n",
    "    approx[approx.<0] = -1\n",
    "    approx = trunc(Int, approx)\n",
    "\n",
    "    adir_train_confusion = zeros(Int, 3, 3)\n",
    "    adir_test_confusion = zeros(Int, 3, 3)\n",
    "    ados_train_confusion = zeros(Int, 3, 3)\n",
    "    ados_test_confusion = zeros(Int, 3, 3)\n",
    "\n",
    "    for i=1:m\n",
    "        for j=adir_indices\n",
    "            if train_data[i, j] != 0\n",
    "                adir_train_confusion[train_data[i, j]+2, approx[i, j]+2] += 1\n",
    "            end\n",
    "            if test_data[i, j] != 0\n",
    "                adir_test_confusion[test_data[i, j]+2, approx[i, j]+2] += 1\n",
    "            end\n",
    "        end\n",
    "        for j=ados_indices\n",
    "            if train_data[i, j] != 0\n",
    "                ados_train_confusion[train_data[i, j]+2, approx[i, j]+2] += 1\n",
    "            end\n",
    "            if test_data[i, j] != 0\n",
    "                ados_test_confusion[test_data[i, j]+2, approx[i, j]+2] += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    push!(error, (adir_test_confusion[1, 3]+adir_test_confusion[3, 1]+ados_test_confusion[1, 3]+ados_test_confusion[3, 1])/(sum(adir_test_confusion)+sum(ados_test_confusion)))\n",
    "    println(\"Error \", (adir_train_confusion[1, 3]+adir_train_confusion[3, 1]+ados_train_confusion[1, 3]+ados_train_confusion[3, 1])/(sum(adir_train_confusion)+sum(ados_train_confusion)), \" \", \n",
    "                    (adir_test_confusion[1, 3]+adir_test_confusion[3, 1]+ados_test_confusion[1, 3]+ados_test_confusion[3, 1])/(sum(adir_test_confusion)+sum(ados_test_confusion)))\n",
    "\n",
    "    push!(adir_error, (adir_test_confusion[1, 3]+adir_test_confusion[3, 1])/sum(adir_test_confusion))\n",
    "    println(\"ADIR \", (adir_train_confusion[1, 3]+adir_train_confusion[3, 1])/sum(adir_train_confusion), \" \", \n",
    "                    (adir_test_confusion[1, 3]+adir_test_confusion[3, 1])/sum(adir_test_confusion))\n",
    "\n",
    "    push!(ados_error, (ados_test_confusion[1, 3]+ados_test_confusion[3, 1])/sum(ados_test_confusion))\n",
    "    println(\"ADOS \", (ados_train_confusion[1, 3]+ados_train_confusion[3, 1])/sum(ados_train_confusion), \" \", \n",
    "                    (ados_test_confusion[1, 3]+ados_test_confusion[3, 1])/sum(ados_test_confusion))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Error 0.23133947061021912 0.23193672509619495\n",
      "2\n",
      "Error 0.7844433806417601 0.20448299028889025\n",
      "3\n",
      "Error 0.17282711330732303 0.19574909912661087\n",
      "4\n",
      "Error 0.7407325012683184 0.19474134245404018\n",
      "5\n",
      "Error 0.1528571918618192 0.1946497282110792\n",
      "6\n",
      "Error 0.46592145814188195 0.19620717034141574\n",
      "7\n",
      "Error 0.1329269899960822 0.19816160752458314\n",
      "8\n",
      "Error 0.72276175473881669 0.19889452146827094\n",
      "9\n",
      "Error 0.11161201914483745 0.19981066389788066\n",
      "10\n",
      "Error 0.08173926442949142 0.20484944726073415\n"
     ]
    }
   ],
   "source": [
    "only_adir_error = []\n",
    "for l=1:10\n",
    "    println(l)\n",
    "    approx = adir_Xs[l].'*adir_Ys[l]\n",
    "    approx[approx.>=0] = 1\n",
    "    approx[approx.<0] = -1\n",
    "    approx = trunc(Int, approx)\n",
    "\n",
    "    adir_train_confusion = zeros(Int, 3, 3)\n",
    "    adir_test_confusion = zeros(Int, 3, 3)\n",
    "\n",
    "    for i=1:m\n",
    "        for j=adir_indices\n",
    "            if train_data[i, j] != 0\n",
    "                adir_train_confusion[train_data[i, j]+2, approx[i, j]+2] += 1\n",
    "            end\n",
    "            if test_data[i, j] != 0\n",
    "                adir_test_confusion[test_data[i, j]+2, approx[i, j]+2] += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    push!(only_adir_error, (adir_test_confusion[1, 3]+adir_test_confusion[3, 1])/(sum(adir_test_confusion)))\n",
    "    println(\"Error \", (adir_train_confusion[1, 3]+adir_train_confusion[3, 1])/(sum(adir_train_confusion)), \" \", \n",
    "                    (adir_test_confusion[1, 3]+adir_test_confusion[3, 1])/(sum(adir_test_confusion)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Error 0.266966095412352 0.28782537960954446\n",
      "2\n",
      "Error 0.249344361459656 0.22674891540130152\n",
      "3\n",
      "Error 0.16835966150618706 0.23386659436008678\n",
      "4\n",
      "Error 0.94489930361128417 0.24017082429501085\n",
      "5\n",
      "Error 0.13606788804151518 0.25935466377440347\n",
      "6\n",
      "Error 0.0615493836604967 0.24857646420824295\n",
      "7\n",
      "Error 0.09444200809167409 0.255558568329718\n",
      "8\n",
      "Error 0.025915224334960605 0.2533215835140998\n",
      "9\n",
      "Error 0.06298122983982271 0.2584056399132321\n",
      "10\n",
      "Error 0.097624369661742784 0.2723698481561822\n"
     ]
    }
   ],
   "source": [
    "only_ados_error = []\n",
    "for l=1:10\n",
    "    println(l)\n",
    "    approx = ados_Xs[l].'*ados_Ys[l]\n",
    "    approx[approx.>=0] = 1\n",
    "    approx[approx.<0] = -1\n",
    "    approx = trunc(Int, approx)\n",
    "\n",
    "    ados_train_confusion = zeros(Int, 3, 3)\n",
    "    ados_test_confusion = zeros(Int, 3, 3)\n",
    "\n",
    "    for i=1:m\n",
    "        for j=ados_indices\n",
    "            if train_data[i, j] != 0\n",
    "                ados_train_confusion[train_data[i, j]+2, approx[i, j-77]+2] += 1\n",
    "            end\n",
    "            if test_data[i, j] != 0\n",
    "                ados_test_confusion[test_data[i, j]+2, approx[i, j-77]+2] += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    push!(only_ados_error, (ados_test_confusion[1, 3]+ados_test_confusion[3, 1])/(sum(ados_test_confusion)))\n",
    "    println(\"Error \", (ados_train_confusion[1, 3]+ados_train_confusion[3, 1])/(sum(ados_train_confusion)), \" \", \n",
    "                    (ados_test_confusion[1, 3]+ados_test_confusion[3, 1])/(sum(ados_test_confusion)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"/Users/kelley/.julia/v0.5/Plots/src/backends/../../deps/plotly-latest.min.js\"></script>    <div id=\"c47cedca-7046-406b-a52b-efb7144cfe03\" style=\"width:600px;height:400px;\"></div>\n",
       "    <script>\n",
       "    PLOT = document.getElementById('c47cedca-7046-406b-a52b-efb7144cfe03');\n",
       "    Plotly.plot(PLOT, [{\"yaxis\":\"y\",\"y\":[0.24415764874310497,0.21485115162743695,0.20775611604699146,0.20198745210324645,0.20120847193566044,0.20287169986104678,0.20337698429407555,0.20493494462924755,0.20537706850814771,0.20828245399806308],\"showlegend\":true,\"name\":\"All Items\",\"type\":\"scatter\",\"xaxis\":\"x\",\"line\":{\"width\":2,\"dash\":\"solid\",\"color\":\"rgba(206, 147, 216, 1.000)\",\"shape\":\"linear\"},\"colorbar\":{\"title\":\"\"},\"x\":[1,2,3,4,5,6,7,8,9,10],\"mode\":\"lines\"},{\"yaxis\":\"y\",\"y\":[0.23138703963842913,0.20888047395101692,0.19776461247175228,0.19251206254198985,0.19300067183778172,0.19153484395040615,0.19275636718988579,0.1943748854821963,0.19379466194344347,0.19645147498931168],\"showlegend\":true,\"name\":\"ADI-R Items\",\"type\":\"scatter\",\"xaxis\":\"x\",\"line\":{\"width\":2,\"dash\":\"solid\",\"color\":\"rgba(239, 108, 0, 1.000)\",\"shape\":\"linear\"},\"colorbar\":{\"title\":\"\"},\"x\":[1,2,3,4,5,6,7,8,9,10],\"mode\":\"lines\"},{\"yaxis\":\"y\",\"y\":[0.2725054229934924,0.22810466377440347,0.2299349240780911,0.22302060737527116,0.21942787418655096,0.22803687635574837,0.2269522776572668,0.22837581344902386,0.23108731019522777,0.23454446854663774],\"showlegend\":true,\"name\":\"ADOS Items\",\"type\":\"scatter\",\"xaxis\":\"x\",\"line\":{\"width\":2,\"dash\":\"solid\",\"color\":\"rgba(77, 182, 172, 1.000)\",\"shape\":\"linear\"},\"colorbar\":{\"title\":\"\"},\"x\":[1,2,3,4,5,6,7,8,9,10],\"mode\":\"lines\"}], {\"yaxis\":{\"type\":\"-\",\"titlefont\":{\"size\":15,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"title\":\"Validation Error\",\"tickfont\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"ticks\":\"inside\",\"tickmode\":\"array\",\"showgrid\":true,\"tickvals\":[0.2,0.225,0.25],\"domain\":[0.07581474190726165,0.9415463692038496],\"ticktext\":[\"0.200\",\"0.225\",\"0.250\"],\"tickangle\":0,\"zeroline\":false,\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"tickcolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"x\"},\"annotations\":[{\"text\":\"Imputation Error as a function of k\",\"y\":1.0,\"xref\":\"paper\",\"font\":{\"size\":20,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"xanchor\":\"center\",\"x\":0.5497685185185185,\"yref\":\"paper\",\"showarrow\":false,\"yanchor\":\"top\",\"rotation\":-0.0}],\"width\":600,\"plot_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"showlegend\":true,\"legend\":{\"bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"y\":1.0,\"font\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"bordercolor\":\"rgba(0, 0, 0, 1.000)\",\"x\":1.0},\"xaxis\":{\"type\":\"-\",\"titlefont\":{\"size\":15,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"title\":\"k\",\"tickfont\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"ticks\":\"inside\",\"tickmode\":\"array\",\"showgrid\":true,\"tickvals\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0],\"domain\":[0.10609871682706327,0.9934383202099737],\"ticktext\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],\"tickangle\":0,\"zeroline\":false,\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"tickcolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"y\"},\"paper_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"height\":400,\"margin\":{\"r\":0,\"l\":0,\"b\":20,\"t\":20}});\n",
       "    </script>\n"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "plotly() # Choose the Plotly.jl backend for web interactivity\n",
    "labels = Array{String}(1, 3)\n",
    "labels[1] = \"All Items\"\n",
    "labels[2] = \"ADI-R Items\"\n",
    "labels[3] = \"ADOS Items\"\n",
    "plot([error, adir_error, ados_error], xticks = 0:1:20, linewidth=2, \n",
    "    title=\"Imputation Error as a function of k\", ylabel=\"Validation Error\", xlabel=\"k\", label=labels,\n",
    "    palette=[\"#ce93d8\", \"#4db6ac\", \"#ef6c00\"])\n",
    "\n",
    "#labels[1] = \"\"\n",
    "#labels[2] = \"ADI-R\"\n",
    "#labels[3] = \"ADOS\"\n",
    "\n",
    "#plot!([[], only_adir_error, only_ados_error], linewidth=2, \n",
    "#    title=\"Single Instrument Imputation Error <br>as a function of k\", ylabel=\"Validation Error\", legend=:right, \n",
    "#    xlabel=\"k\", xticks = 0:1:10, label=labels, palette = [\"#ce93d8\", \"#4db6ac\", \"#ef6c00\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"/Users/kelley/.julia/v0.5/Plots/src/backends/../../deps/plotly-latest.min.js\"></script>    <div id=\"15c27c0d-544c-4e8b-866f-cc1318e84c3b\" style=\"width:600px;height:400px;\"></div>\n",
       "    <script>\n",
       "    PLOT = document.getElementById('15c27c0d-544c-4e8b-866f-cc1318e84c3b');\n",
       "    Plotly.plot(PLOT, [{\"yaxis\":\"y\",\"y\":[],\"showlegend\":false,\"name\":\"\",\"type\":\"scatter\",\"xaxis\":\"x\",\"line\":{\"width\":2,\"dash\":\"solid\",\"color\":\"rgba(206, 147, 216, 1.000)\",\"shape\":\"linear\"},\"colorbar\":{\"title\":\"\"},\"x\":[],\"mode\":\"lines\"},{\"yaxis\":\"y\",\"y\":[0.23193672509619495,0.20448299028889025,0.19574909912661087,0.19474134245404018,0.1946497282110792,0.19620717034141574,0.19816160752458314,0.19889452146827094,0.19981066389788066,0.20484944726073415],\"showlegend\":true,\"name\":\"ADI-R\",\"type\":\"scatter\",\"xaxis\":\"x\",\"line\":{\"width\":2,\"dash\":\"solid\",\"color\":\"rgba(239, 108, 0, 1.000)\",\"shape\":\"linear\"},\"colorbar\":{\"title\":\"\"},\"x\":[1,2,3,4,5,6,7,8,9,10],\"mode\":\"lines\"},{\"yaxis\":\"y\",\"y\":[0.28782537960954446,0.22674891540130152,0.23386659436008678,0.24017082429501085,0.25935466377440347,0.24857646420824295,0.255558568329718,0.2533215835140998,0.2584056399132321,0.2723698481561822],\"showlegend\":true,\"name\":\"ADOS\",\"type\":\"scatter\",\"xaxis\":\"x\",\"line\":{\"width\":2,\"dash\":\"solid\",\"color\":\"rgba(77, 182, 172, 1.000)\",\"shape\":\"linear\"},\"colorbar\":{\"title\":\"\"},\"x\":[1,2,3,4,5,6,7,8,9,10],\"mode\":\"lines\"}], {\"yaxis\":{\"type\":\"-\",\"titlefont\":{\"size\":15,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"title\":\"Validation Error\",\"tickfont\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"ticks\":\"inside\",\"tickmode\":\"array\",\"showgrid\":true,\"tickvals\":[0.2,0.22,0.24,0.26,0.28],\"domain\":[0.07581474190726165,0.9415463692038496],\"ticktext\":[\"0.20\",\"0.22\",\"0.24\",\"0.26\",\"0.28\"],\"tickangle\":0,\"zeroline\":false,\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"tickcolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"x\"},\"annotations\":[{\"text\":\"Single Instrument Imputation Error <br>as a function of k\",\"y\":1.0,\"xref\":\"paper\",\"font\":{\"size\":20,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"xanchor\":\"center\",\"x\":0.5423611111111111,\"yref\":\"paper\",\"showarrow\":false,\"yanchor\":\"top\",\"rotation\":-0.0}],\"width\":600,\"plot_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"showlegend\":true,\"legend\":{\"bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"y\":0.5,\"font\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"bordercolor\":\"rgba(0, 0, 0, 1.000)\",\"x\":1.0},\"xaxis\":{\"type\":\"-\",\"titlefont\":{\"size\":15,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"title\":\"k\",\"tickfont\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"ticks\":\"inside\",\"tickmode\":\"array\",\"showgrid\":true,\"tickvals\":[1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0],\"domain\":[0.09128390201224845,0.9934383202099738],\"ticktext\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"],\"tickangle\":0,\"zeroline\":false,\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"tickcolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"y\"},\"paper_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"height\":400,\"margin\":{\"r\":0,\"l\":0,\"b\":20,\"t\":20}});\n",
       "    </script>\n"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "plotly() # Choose the Plotly.jl backend for web interactivity\n",
    "labels = Array{String}(1, 3)\n",
    "labels[1] = \"\"\n",
    "labels[2] = \"ADI-R\"\n",
    "labels[3] = \"ADOS\"\n",
    "\n",
    "plot([[], only_adir_error, only_ados_error], linewidth=2, \n",
    "    title=\"Single Instrument Imputation Error <br>as a function of k\", ylabel=\"Validation Error\", legend=:right, \n",
    "    xlabel=\"k\", xticks = 0:1:10, label=labels, palette = [\"#ce93d8\", \"#4db6ac\", \"#ef6c00\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx = Xs[6].'*Ys[6]\n",
    "#i_values = approx[heldout_data .!= 0]\n",
    "#a_values = heldout_data[heldout_data .!= 0]\n",
    "i_values = approx[adir_heldout_indices, adir_indices][:]\n",
    "a_values = all_data[adir_heldout_indices, adir_indices][:]\n",
    "#i_values = approx[ados_heldout_indices, ados_indices][:]\n",
    "#a_values = all_data[ados_heldout_indices, ados_indices][:]\n",
    "\n",
    "roc_values = sort(collect(zip(i_values, a_values)))\n",
    "tp = sum(map(x -> x[2] > 0, roc_values))\n",
    "fp = sum(map(x -> x[2] < 0, roc_values))\n",
    "tn = 0\n",
    "fn = 0\n",
    "sensitivity = Array(Float64, 0)\n",
    "specificity = Array(Float64, 0)\n",
    "cutoffs = Array(Float64, 0)\n",
    "push!(sensitivity, 1)\n",
    "push!(specificity, 0)\n",
    "push!(cutoffs, 0)\n",
    "for v=roc_values\n",
    "    if v[2] > 0 \n",
    "        tp -=1\n",
    "        fn += 1\n",
    "    elseif v[2] < 0\n",
    "        fp -= 1\n",
    "        tn += 1\n",
    "    end\n",
    "    if (abs(tp/(tp+fn) - sensitivity[end]) > .1) || (abs(tn/(tn+fp) - specificity[end]) > .1)\n",
    "        push!(sensitivity, tp/(tp+fn))\n",
    "        push!(specificity, tn/(tn+fp))\n",
    "        push!(cutoffs, v[1])\n",
    "    end\n",
    "end\n",
    "push!(sensitivity, 0)\n",
    "push!(specificity, 1)\n",
    "baseline_index = findfirst(x -> x > 0, cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx = Xs[5].'*Ys[5]\n",
    "i_values = approx[heldout_data .!= 0]\n",
    "a_values = heldout_data[heldout_data .!= 0]\n",
    "roc_values = sort(collect(zip(i_values, a_values)))\n",
    "tp = sum(map(x -> x[2] > 0, roc_values))\n",
    "fp = sum(map(x -> x[2] < 0, roc_values))\n",
    "tn = 0\n",
    "fn = 0\n",
    "sensitivity = Array(Float64, 0)\n",
    "specificity = Array(Float64, 0)\n",
    "cutoffs = Array(Float64, 0)\n",
    "push!(sensitivity, 1)\n",
    "push!(specificity, 0)\n",
    "push!(cutoffs, 0)\n",
    "for v=roc_values\n",
    "    if v[2] > 0 \n",
    "        tp -=1\n",
    "        fn += 1\n",
    "    elseif v[2] < 0\n",
    "        fp -= 1\n",
    "        tn += 1\n",
    "    end\n",
    "    if (abs(tp/(tp+fn) - sensitivity[end]) > .1) || (abs(tn/(tn+fp) - specificity[end]) > .1)\n",
    "        push!(sensitivity, tp/(tp+fn))\n",
    "        push!(specificity, tn/(tn+fp))\n",
    "        push!(cutoffs, v[1])\n",
    "    end\n",
    "end\n",
    "push!(sensitivity, 0)\n",
    "push!(specificity, 1)\n",
    "baseline_index = findfirst(x -> x > 0, cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx = adir_Xs[6].'*adir_Ys[6]\n",
    "adir_heldout_data = heldout_data[:, adir_indices]\n",
    "i_values = approx[adir_heldout_data .!= 0]\n",
    "a_values = adir_heldout_data[adir_heldout_data .!= 0]\n",
    "roc_values = sort(collect(zip(i_values, a_values)))\n",
    "tp = sum(map(x -> x[2] > 0, roc_values))\n",
    "fp = sum(map(x -> x[2] < 0, roc_values))\n",
    "tn = 0\n",
    "fn = 0\n",
    "adir_sensitivity = Array(Float64, 0)\n",
    "adir_specificity = Array(Float64, 0)\n",
    "adir_cutoffs = Array(Float64, 0)\n",
    "push!(adir_sensitivity, 1)\n",
    "push!(adir_specificity, 0)\n",
    "push!(adir_cutoffs, 0)\n",
    "for v=roc_values\n",
    "    if v[2] > 0 \n",
    "        tp -=1\n",
    "        fn += 1\n",
    "    elseif v[2] < 0\n",
    "        fp -= 1\n",
    "        tn += 1\n",
    "    end\n",
    "    if (abs(tp/(tp+fn) - adir_sensitivity[end]) > .1) || (abs(tn/(tn+fp) - adir_specificity[end]) > .1)\n",
    "        push!(adir_sensitivity, tp/(tp+fn))\n",
    "        push!(adir_specificity, tn/(tn+fp))\n",
    "        push!(adir_cutoffs, v[1])\n",
    "    end\n",
    "end\n",
    "push!(adir_sensitivity, 0)\n",
    "push!(adir_specificity, 1)\n",
    "adir_baseline_index = findfirst(x -> x > 0, adir_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "approx = ados_Xs[3].'*ados_Ys[3]\n",
    "ados_heldout_data = heldout_data[:, ados_indices]\n",
    "i_values = approx[ados_heldout_data .!= 0]\n",
    "a_values = ados_heldout_data[ados_heldout_data .!= 0]\n",
    "roc_values = sort(collect(zip(i_values, a_values)))\n",
    "tp = sum(map(x -> x[2] > 0, roc_values))\n",
    "fp = sum(map(x -> x[2] < 0, roc_values))\n",
    "tn = 0\n",
    "fn = 0\n",
    "ados_sensitivity = Array(Float64, 0)\n",
    "ados_specificity = Array(Float64, 0)\n",
    "ados_cutoffs = Array(Float64, 0)\n",
    "push!(ados_sensitivity, 1)\n",
    "push!(ados_specificity, 0)\n",
    "push!(ados_cutoffs, 0)\n",
    "for v=roc_values\n",
    "    if v[2] > 0 \n",
    "        tp -=1\n",
    "        fn += 1\n",
    "    elseif v[2] < 0\n",
    "        fp -= 1\n",
    "        tn += 1\n",
    "    end\n",
    "    if (abs(tp/(tp+fn) - ados_sensitivity[end]) > .1) || (abs(tn/(tn+fp) - ados_specificity[end]) > .1)\n",
    "        push!(ados_sensitivity, tp/(tp+fn))\n",
    "        push!(ados_specificity, tn/(tn+fp))\n",
    "        push!(ados_cutoffs, v[1])\n",
    "    end\n",
    "end\n",
    "push!(ados_sensitivity, 0)\n",
    "push!(ados_specificity, 1)\n",
    "ados_baseline_index = findfirst(x -> x > 0, ados_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6393071571523873"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "zero_impute = zeros()\n",
    "baseline_impute[baseline_impute.<0] = -1\n",
    "baseline_impute[baseline_impute.>0] = 1\n",
    "\n",
    "i_values = baseline_impute[heldout_data .!= 0]\n",
    "a_values = heldout_data[heldout_data .!= 0]\n",
    "\n",
    "tp = count(x -> x[1] == 1 && x[2] == 1, zip(i_values, a_values))\n",
    "tn = count(x -> x[1] == -1 && x[2] == -1, zip(i_values, a_values))\n",
    "fp = count(x -> x[1] == 1 && x[2] == -1, zip(i_values, a_values))\n",
    "fn = count(x -> x[1] == -1 && x[2] == 1, zip(i_values, a_values))\n",
    "\n",
    "baseline_sensitivity = tp/(tp+fn)\n",
    "baseline_specificity = tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"/Users/kelley/.julia/v0.5/Plots/src/backends/../../deps/plotly-latest.min.js\"></script>    <div id=\"0e6ee42d-2f46-49bb-9b17-2d5ed85c86aa\" style=\"width:500px;height:400px;\"></div>\n",
       "    <script>\n",
       "    PLOT = document.getElementById('0e6ee42d-2f46-49bb-9b17-2d5ed85c86aa');\n",
       "    Plotly.plot(PLOT, [{\"yaxis\":\"y\",\"y\":[1.0,0.9993210877682647,0.9975295138234074,0.9938520725681741,0.9860822992494248,0.9722588918643684,0.9498359295439973,0.9146645042054841,0.8531663712141214,0.7531588277448799,0.6531512842756384,0.5531437408063968,0.4531361973371554,0.35312865386791387,0.25312111039867236,0.15311356692943084,0.05310602346018934,0.0],\"showlegend\":true,\"name\":\"GLRM Impute<br>k=5\",\"type\":\"scatter\",\"xaxis\":\"x\",\"line\":{\"width\":2,\"dash\":\"solid\",\"color\":\"rgba(206, 147, 216, 1.000)\",\"shape\":\"linear\"},\"colorbar\":{\"title\":\"\"},\"x\":[1.0,0.8999809396740684,0.7999618793481369,0.6999428190222052,0.5999237586962737,0.4999046983703421,0.3998856380444106,0.299866577718479,0.19984751739254736,0.11169350995902028,0.06416182216715904,0.03630992089964735,0.019441532450204857,0.009577813780615618,0.004074144667873814,0.001620127704183738,0.0005241589631183041,0.0],\"mode\":\"lines\"},{\"yaxis\":\"y\",\"showlegend\":false,\"type\":\"scatter\",\"xaxis\":\"x\",\"name\":\"y2\",\"marker\":{\"symbol\":\"hexagon\",\"line\":{\"width\":1,\"color\":\"rgba(0, 0, 0, 1.000)\"},\"size\":10,\"color\":\"rgba(206, 147, 216, 1.000)\"},\"y\":[0.8531663712141214],\"line\":{\"width\":1,\"dash\":\"solid\",\"color\":\"rgba(206, 147, 216, 1.000)\",\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"colorbar\":{\"title\":\"\"},\"x\":[0.19984751739254736]},{\"yaxis\":\"y\",\"showlegend\":true,\"type\":\"scatter\",\"xaxis\":\"x\",\"name\":\"Median Impute\",\"marker\":{\"symbol\":\"hexagon\",\"line\":{\"width\":1,\"color\":\"rgba(0, 0, 0, 1.000)\"},\"size\":10,\"color\":\"rgba(239, 108, 0, 1.000)\"},\"y\":[0.8393995398483762],\"line\":{\"width\":1,\"dash\":\"solid\",\"color\":\"rgba(239, 108, 0, 1.000)\",\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"colorbar\":{\"title\":\"\"},\"x\":[0.3606928428476127]}], {\"yaxis\":{\"type\":\"-\",\"titlefont\":{\"size\":15,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"title\":\"Sensitivity\",\"tickfont\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"ticks\":\"inside\",\"tickmode\":\"array\",\"showgrid\":true,\"tickvals\":[0.0,0.2,0.4,0.6,0.8,1.0],\"domain\":[0.11518482064741913,0.9021762904636921],\"ticktext\":[\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\"],\"tickangle\":0,\"zeroline\":false,\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"tickcolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"x\"},\"annotations\":[{\"text\":\"Imputation ROC\",\"y\":1.0,\"xref\":\"paper\",\"font\":{\"size\":20,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"xanchor\":\"center\",\"x\":0.5419444444444445,\"yref\":\"paper\",\"showarrow\":false,\"yanchor\":\"top\",\"rotation\":-0.0}],\"width\":500,\"plot_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"showlegend\":true,\"legend\":{\"bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"y\":0.5,\"font\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"bordercolor\":\"rgba(0, 0, 0, 1.000)\",\"x\":1.0},\"xaxis\":{\"type\":\"-\",\"titlefont\":{\"size\":15,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"title\":\"1-Specificity\",\"tickfont\":{\"size\":11,\"color\":\"rgba(0, 0, 0, 1.000)\",\"family\":\"sans-serif\"},\"ticks\":\"inside\",\"tickmode\":\"array\",\"showgrid\":true,\"tickvals\":[0.0,0.2,0.4,0.6,0.8,1.0],\"domain\":[0.12325896762904637,0.9606299212598426],\"ticktext\":[\"0.0\",\"0.2\",\"0.4\",\"0.6\",\"0.8\",\"1.0\"],\"tickangle\":0,\"zeroline\":false,\"linecolor\":\"rgba(0, 0, 0, 1.000)\",\"tickcolor\":\"rgba(0, 0, 0, 1.000)\",\"anchor\":\"y\"},\"paper_bgcolor\":\"rgba(255, 255, 255, 1.000)\",\"height\":400,\"margin\":{\"r\":0,\"l\":0,\"b\":20,\"t\":20}});\n",
       "    </script>\n"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "plotly() # Choose the Plotly.jl backend for web interactivity\n",
    "plot(1-specificity, sensitivity, linewidth=2, \n",
    "    title=\"Imputation ROC\", ylabel=\"Sensitivity\", xlabel=\"1-Specificity\", linewidth=2, label=\"GLRM Impute<br>k=5\", primary=true,\n",
    "    palette=[\"#ce93d8\", \"#4db6ac\", \"#ef6c00\"], xticks = 0:.2:1, yticks = 0:.2:1, size=(500, 400), legend=:right, margin=5mm)\n",
    "plot!([1-specificity[baseline_index]], [sensitivity[baseline_index]], markersize=5, markershape = :hexagon, primary=false)\n",
    "\n",
    "plot!([1-baseline_specificity], [baseline_sensitivity], markersize=5, markershape = :hexagon, primary=true, label=\"Median Impute\")\n",
    "\n",
    "\n",
    "#plot!(1-adir_specificity, adir_sensitivity, linewidth=2, \n",
    "#    linewidth=2, label=\"ADI-R\", primary=true,\n",
    "#    palette=[\"#ce93d8\", \"#4db6ac\", \"#ef6c00\"], xticks = 0:.2:1, yticks = 0:.2:1)\n",
    "#plot!([1-adir_specificity[adir_baseline_index]], [adir_sensitivity[adir_baseline_index]], markersize=5, markershape = :hexagon, primary=false, label=\"ADI-R\")\n",
    "\n",
    "#plot!(1-ados_specificity, ados_sensitivity, linewidth=2, \n",
    "#    linewidth=2, label=\"ADOS\",primary=true,\n",
    "#    palette=[\"#ce93d8\", \"#4db6ac\", \"#ef6c00\"], xticks = 0:.2:1, yticks = 0:.2:1)\n",
    "#plot!([1-ados_specificity[ados_baseline_index]], [ados_sensitivity[ados_baseline_index]], markersize=5, markershape = :hexagon, primary=false, label=\"ADOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "approx = Xs[k].'*Ys[k]\n",
    "approx[approx.>=0] = 1\n",
    "approx[approx.<0] = 0\n",
    "approx = trunc(Int, approx)\n",
    "\n",
    "# Replace imputed values with real values if we have them\n",
    "approx[all_data.>0] = 1\n",
    "approx[all_data.<0] = 0\n",
    "\n",
    "new_df = convert(DataFrame, approx)\n",
    "names!(new_df, names(df))\n",
    "new_df = hcat(samples, new_df)\n",
    "\n",
    "writecsv(\"../data/impute_logloss_X$(k).csv\", Xs[k])\n",
    "writecsv(\"../data/impute_logloss_Y$(k).csv\", Ys[k])\n",
    "writetable(\"../data/impute_logloss_realfill_Z$(k).csv\", new_df, separator = ',', header = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = 6\n",
    "approx = adir_Xs[k].'*adir_Ys[k]\n",
    "approx[approx.>=0] = 1\n",
    "approx[approx.<0] = 0\n",
    "approx = trunc(Int, approx)\n",
    "\n",
    "# Replace imputed values with real values if we have them\n",
    "approx[all_data[:, adir_indices].>0] = 1\n",
    "approx[all_data[:, adir_indices].<0] = 0\n",
    "\n",
    "new_df = convert(DataFrame, approx)\n",
    "names!(new_df, names(df)[1:size(approx, 2)])\n",
    "new_df = hcat(samples, new_df)\n",
    "\n",
    "writecsv(\"../data/impute_logloss_adir_realfill_X$(k).csv\", adir_Xs[k])\n",
    "writecsv(\"../data/impute_logloss_adir_realfill_Y$(k).csv\", adir_Ys[k])\n",
    "writetable(\"../data/impute_logloss_adir_realfill_Z$(k).csv\", new_df, separator = ',', header = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 6\n",
    "approx = ados_Xs[k].'*ados_Ys[k]\n",
    "approx[approx.>=0] = 1\n",
    "approx[approx.<0] = 0\n",
    "approx = trunc(Int, approx)\n",
    "\n",
    "# Replace imputed values with real values if we have them\n",
    "approx[all_data[:, ados_indices].>0] = 1\n",
    "approx[all_data[:, ados_indices].<0] = 0\n",
    "\n",
    "new_df = convert(DataFrame, approx)\n",
    "names!(new_df, names(df)[(end-size(approx, 2)+1):end])\n",
    "new_df = hcat(samples, new_df)\n",
    "\n",
    "writecsv(\"../data/impute_logloss_ados_realfill_X$(k).csv\", adir_Xs[k])\n",
    "writecsv(\"../data/impute_logloss_ados_realfill_Y$(k).csv\", adir_Ys[k])\n",
    "writetable(\"../data/impute_logloss_ados_realfill_Z$(k).csv\", new_df, separator = ',', header = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
